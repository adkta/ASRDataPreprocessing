{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7nypM6RjowBB0GzfrdeV2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##DESIGN\n",
        "\"\"\"\n",
        "Preprocessing\n",
        "\n",
        "  Convert To Mono\n",
        "  Audio Enhancement (optional)\n",
        "  Label transliteration\n",
        "  Remove punctuation\n",
        "  Augmentation\n",
        "  Label copying\n",
        "  Necessary folder arrangement to load data and feed into wav2vec2\n",
        "\n",
        "\n",
        "Data\n",
        "  Folder1\n",
        "    audio_1\n",
        "    audio_2\n",
        "    ...\n",
        "    transcript    \n",
        "  Folder2\n",
        "    audio_1\n",
        "    audio_2\n",
        "    ...\n",
        "    transcript\n",
        "  ...\n",
        "\n",
        "DataFolderPath\n",
        "->\n",
        "Preprocessor\n",
        "(walks data folder)\n",
        "searches for transcript file, finds file and creates transliterated transcript file/ generates a pandas transliterated row for the file.\n",
        "Each audio is augmented (list of augmentation is provided) corresponding label\n",
        "->\n",
        "Transliteration using dictionary\n",
        "->\n",
        "Augmentation\n",
        "->\n",
        "Label Copy\n",
        "->\n",
        "Folder format\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "D8gy1vonp0l0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SETUP"
      ],
      "metadata": {
        "id": "FX0PnyeYNp8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install g2p_en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-CF91aBswAD",
        "outputId": "b4a5250d-f0f5-48b9-d94f-1a64b7afe386"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting g2p_en\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.12/dist-packages (from g2p_en) (2.0.2)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.12/dist-packages (from g2p_en) (3.9.1)\n",
            "Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from g2p_en) (7.5.0)\n",
            "Collecting distance>=0.1.3 (from g2p_en)\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.12/dist-packages (from inflect>=0.3.1->g2p_en) (10.8.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from inflect>=0.3.1->g2p_en) (4.4.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (4.67.1)\n",
            "Requirement already satisfied: typing_extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from typeguard>=4.0.1->inflect>=0.3.1->g2p_en) (4.15.0)\n",
            "Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: distance\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16256 sha256=b0a46c1dbb212df93a9b9f47ef06b6bf7fb70124c6b023b797207f89cd565bdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/a8/58/407063d8e5c1d4dd6594c99d12baa0108570b56a92325587dd\n",
            "Successfully built distance\n",
            "Installing collected packages: distance, g2p_en\n",
            "Successfully installed distance-0.1.3 g2p_en-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dXhHz3vIi_CG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b8752b-f719-4165-c17c-1383d5ff9ff0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/transliteration"
      ],
      "metadata": {
        "id": "phuzjpfuM1WS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16410ab-f6b3-4c73-dd7e-1478a8d45fd9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/transliteration': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/adkta/transliteration.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3H9FIY5pBet",
        "outputId": "ff751435-f012-49b0-d5fb-3aa8391ce687"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transliteration'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 108 (delta 57), reused 77 (delta 29), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (108/108), 26.16 KiB | 1.63 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBWr2FVIullx",
        "outputId": "90ab8857-935e-472b-aeca-e22aa622342a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.12/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from typing import Union, Optional\n",
        "from pathlib import Path\n",
        "from transliteration.transliterator import Transliterator\n",
        "from transliteration.transliterators import RomanToDevaTransliterator\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections.abc import Generator"
      ],
      "metadata": {
        "id": "yegl7DcSVXKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d586562-77a3-4386-ef96-0ad634d63fac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/transliteration/transliterator.py:123: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  label.strip('\\s,\"?.|')\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transliteration.transliterator import TranslitDict"
      ],
      "metadata": {
        "id": "ONGdQx675b2e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LOGGING CONFIGURATION"
      ],
      "metadata": {
        "id": "WzAjhysBdPt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "LOG_LEVEL = logging.INFO\n",
        "_log_path = '/content/preprocessing.log'\n",
        "logger = logging.getLogger(\"preprocessing\")\n",
        "logger.setLevel(LOG_LEVEL)\n",
        "_handler = logging.FileHandler(_log_path)\n",
        "_handler.setLevel(LOG_LEVEL)\n",
        "_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
        "logger.addHandler(_handler)"
      ],
      "metadata": {
        "id": "YIiuVD4X6FMa"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PREPROCESSING CLASSES"
      ],
      "metadata": {
        "id": "Kyk5CNuBQ_WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Utils:\n",
        "    @staticmethod\n",
        "    def get_matching_files(data_fol: Path, file_pattern: str) -> Generator[Path, None, None]:\n",
        "        file_pattern = re.compile(file_pattern)\n",
        "        for f in data_fol.iterdir():\n",
        "            if file_pattern.search(f.as_posix()):\n",
        "                yield f"
      ],
      "metadata": {
        "id": "mcA-IIERLZy4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "onbtow9TtXMo"
      },
      "outputs": [],
      "source": [
        "import torchaudio\n",
        "import torch\n",
        "\n",
        "class AudioAugmentor:\n",
        "    def __init__(self) -> None:\n",
        "        self.download_assets()\n",
        "\n",
        "    def download_assets(self) -> None:\n",
        "        rir_loc = torchaudio.utils.download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo-8000hz.wav\")\n",
        "        noise_loc = torchaudio.utils.download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo-8000hz.wav\")\n",
        "        self.rir, self.rir_sample_rate = torchaudio.load(rir_loc)\n",
        "        self.noise, self.noise_sample_rate = torchaudio.load(noise_loc)\n",
        "        self.noise = self.noise/torch.linalg.vector_norm(self.noise)\n",
        "\n",
        "    def resample_assets(self, new_sample_rate: int) -> None:\n",
        "        self.rir = torchaudio.transforms.Resample(orig_freq=self.rir_sample_rate, new_freq=new_sample_rate)(self.rir)\n",
        "        self.noise = torchaudio.transforms.Resample(orig_freq=self.noise_sample_rate, new_freq=new_sample_rate)(self.noise)\n",
        "\n",
        "    def frame_count(self, waveform: torch.Tensor) -> int:\n",
        "        return waveform.shape[1]\n",
        "\n",
        "    def adjust_noise_frame_count_for_add(self, waveform: torch.Tensor, noise: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Noise adjustment for addition to signal\n",
        "        \"\"\"\n",
        "        noise_frame_count = self.frame_count(noise)\n",
        "        signal_frame_count = self.frame_count(waveform)\n",
        "        if noise_frame_count == signal_frame_count:\n",
        "            pass\n",
        "        elif noise_frame_count > signal_frame_count:\n",
        "            noise = noise[:, :signal_frame_count]\n",
        "        else:\n",
        "            quo, rem= divmod(signal_frame_count, noise_frame_count)\n",
        "            repeated_noise_list=[]\n",
        "            for _ in range(quo):\n",
        "                repeated_noise_list.append(noise)\n",
        "            repeated_noise_list.append(noise[:, :rem])\n",
        "            noise = torch.cat(repeated_noise_list, dim = 1)\n",
        "        return noise\n",
        "\n",
        "    def validate_audio_data(self, audio_data: Union[str, Path, torch.Tensor]) -> torch.Tensor:\n",
        "        assert audio_data.is_file(), \"audio_data must be a torch.Tensor, str path to an audio file or Path object to an audio file\"\n",
        "\n",
        "    def convert_to_mono(self, audio_tensor: torch.Tensor) -> torch.Tensor:\n",
        "        if audio_tensor.shape[0] == 1:\n",
        "            return audio_tensor\n",
        "        return torch.mean(audio_tensor, dim=0, keepdim=True)\n",
        "\n",
        "    def resample(self, waveform: torch.Tensor, orig_sample_rate: int, new_sample_rate: int) -> torch.Tensor:\n",
        "        return torchaudio.transforms.Resample(orig_freq=orig_sample_rate, new_freq=new_sample_rate)(waveform)\n",
        "\n",
        "    def shift_pitch(self, audio_data: torch.Tensor, sample_rate: int) -> torch.Tensor:\n",
        "        return torchaudio.transforms.PitchShift(sample_rate = sample_rate, n_steps = 2)(audio_data)\n",
        "\n",
        "    def add_background_crowd(self, audio_data: torch.Tensor, snr: int) -> torch.Tensor:\n",
        "        adj_resampled_noise = self.adjust_noise_frame_count_for_add(waveform = audio_data, noise = self.noise)\n",
        "        add_noise = torchaudio.transforms.AddNoise()\n",
        "        noisy_audio = add_noise(waveform = audio_data, noise = adj_resampled_noise, snr = torch.tensor([snr]))\n",
        "        return noisy_audio\n",
        "\n",
        "    def add_white_noise(self, audio_data: torch.Tensor, snr: int, variance: int) -> torch.Tensor:\n",
        "        white_noise = torch.randn_like(audio_data) * variance\n",
        "        white_noisy_audio = torchaudio.functional.add_noise(audio_data, white_noise,snr=torch.tensor([snr]))\n",
        "        return white_noisy_audio\n",
        "\n",
        "    def add_room_reverb(self, audio_data: torch.Tensor) -> torch.Tensor:\n",
        "        return torchaudio.functional.fftconvolve(audio_data, self.rir)\n",
        "\n",
        "    def perturb_speed(self, audio_data: torch.Tensor, sample_rate: int, factors: list[float]) -> torch.Tensor:\n",
        "        speed_perturb = torchaudio.transforms.SpeedPerturbation(orig_freq= sample_rate, factors = factors)\n",
        "        perturbed_audio, _ = speed_perturb(waveform = audio_data)\n",
        "        return perturbed_audio\n",
        "\n",
        "    def apply_low_pass_filter(self, audio_data: torch.Tensor, sample_rate: int) -> torch.Tensor:\n",
        "        req_effect = \"lowpass=frequency=1000\"\n",
        "        effector = torchaudio.io.AudioEffector(effect=req_effect)\n",
        "        filtered_audio_list = []\n",
        "        for chunk in effector.stream(waveform=audio_data.T, sample_rate = sample_rate, frames_per_chunk = 48000):\n",
        "            filtered_audio_list.append(chunk)\n",
        "        filtered_audio = torch.cat(filtered_audio_list, dim=0).T\n",
        "        return filtered_audio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import IO\n",
        "from transliteration.transliterator import Transliterator\n",
        "\n",
        "\n",
        "class AudioPreprocessor:\n",
        "    \"\"\"\n",
        "    Audio identifiers in the transcript file will only be searched non-recursively in the folder housing the transcript file.\n",
        "    Currently the preprocessor expects the following format in the transcript file.\n",
        "    Each line corresponds to audio_<audio_number>.<audio_ext>. Eg. line 1 would be for audio_1.mp3, line 2 for audio_2.mp3 and so on.\n",
        "    A future to do may process the file in format: audio_id<delimiter>label (which is the output format)\n",
        "    \"\"\"\n",
        "\n",
        "    audio_ext_pattern = r\"\\.mp3$|\\.wav$|\\.opus$\"\n",
        "    DEFAULT_RESAMPLE_RATE = 16000\n",
        "    TKNZR_PATTERN = re.compile(TranslitDict.PUNCT_SPACE_REGEX)\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_folder: str,\n",
        "        out_folder: str,\n",
        "        skip: Union[tuple[str],None] = None,\n",
        "        transcr_name:tuple[str] = (\"transcript.txt\",),\n",
        "        out_transcr_name: str = \"transcript.txt\",\n",
        "        transliterator: Optional[Transliterator] = None,\n",
        "        save_aud: bool = True,\n",
        "        augmentor: Optional[AudioAugmentor] = None,\n",
        "        mono: bool = True,\n",
        "        resample_rate: Optional[int] = DEFAULT_RESAMPLE_RATE,\n",
        "        augment: bool = False\n",
        "        ) -> None:\n",
        "        \"\"\"\n",
        "        :param data_folder: str Input data folder\n",
        "        :param out_folder: str Output folder\n",
        "        :param skip: Union[tuple[str], None] List of files/folders to skip\n",
        "        :param transcr_name: str List of names that qualify as transcript files\n",
        "        :param transliterator: Optional[Transliterator] Transliterator to use. If not specified will not transliterate labels\n",
        "        :param augmentor: Augmentor Augmentor to use. If not specified, will not augment the audio\n",
        "        :param mono: bool Convert to mono channel\n",
        "        :param resample_rate: int Resample rate\n",
        "        \"\"\"\n",
        "        self.data_folder = Path(data_folder)\n",
        "        self.out_folder = Path(out_folder)\n",
        "        self.skip = skip\n",
        "        self.transcr_name = transcr_name\n",
        "        self.out_transcr_name = out_transcr_name\n",
        "        self.transliterator = transliterator\n",
        "        self.save_aud = save_aud\n",
        "        self.augmentor = augmentor\n",
        "        self.mono = mono\n",
        "        self.resample_rate = resample_rate\n",
        "        self.augment = augment\n",
        "\n",
        "    def is_audio(self, path: Path) -> bool:\n",
        "        return path.is_file() and path.name.endswith(AudioPreprocessor.audio_ext)\n",
        "\n",
        "    def get_transcr_file(self, folder: Path) -> Optional[Path]:\n",
        "        transcript_files = []\n",
        "        for fn in self.transcr_name:\n",
        "            logger.info(f\"Searching for {fn} in {folder}\")\n",
        "            if transcript_file := list(folder.glob(fn)):\n",
        "                transcript_files.extend(transcript_file)\n",
        "\n",
        "        assert len(transcript_files) < 2, \"More than one transcript file\"\n",
        "        return transcript_files[0] if transcript_files else None\n",
        "\n",
        "    def get_audio_files(self, folder: Path) -> Generator[Path, None, None]:\n",
        "        return Utils.get_matching_files(data_fol = folder, file_pattern = AudioPreprocessor.audio_ext_pattern)\n",
        "\n",
        "    def get_transcripts(self, transcript_file: Path) -> Generator[str, None, None]:\n",
        "        punctuations = ',\"?.|'\n",
        "        spaces = '\\s'\n",
        "        removable = punctuations + spaces\n",
        "        with open(transcript_file, 'r') as f:\n",
        "            for line in f:\n",
        "                line = line.strip(removable)\n",
        "                if not line:\n",
        "                  continue\n",
        "                if self.transliterator:\n",
        "                  line = self.transliterate_line(line)\n",
        "                line = line.replace(removable, '')\n",
        "                yield line\n",
        "\n",
        "    def transliterate_line(self, line: str) -> str:\n",
        "        words = AudioPreprocessor.TKNZR_PATTERN.split(line)\n",
        "        tl_words = []\n",
        "        for word in words:\n",
        "            if self.transliterator.for_transliteration(word):\n",
        "                word = self.transliterator.translit(word)\n",
        "            tl_words.append(word)\n",
        "        return \" \".join(tl_words)\n",
        "\n",
        "    def get_audio_label_dict(self, folder: Path) -> Optional[dict[Path, str]]:\n",
        "        transcript_file = self.get_transcr_file(folder)\n",
        "        if not transcript_file:\n",
        "            return None\n",
        "        numbered_audio_filter = lambda x: len(x.stem.split('_')) == 2\n",
        "        audio_num = lambda x: int(x.stem.split('_')[1])\n",
        "        sorted_audio_path: list[Path] = sorted(filter(numbered_audio_filter, self.get_audio_files(folder)), key = audio_num)\n",
        "        transcripts: Generator[str, None, None] = self.get_transcripts(transcript_file)\n",
        "        audio_label_dict:dict[Path, str] = dict(zip(sorted_audio_path, transcripts))\n",
        "        return audio_label_dict\n",
        "\n",
        "    def write_to_transcript(self, audio_path: Path, label: str, out_transcr_file: IO, ext: bool = False) -> None:\n",
        "        audio_id = audio_path.stem #additional assignment for code readability. Con: requires 2 assignment statements if ext = True.\n",
        "        if ext:\n",
        "            audio_id = audio_path.name\n",
        "        logger.debug(f\"Writing to {out_transcr_file}\")\n",
        "        out_transcr_file.write(f\"{audio_id}\\t{label}\")\n",
        "\n",
        "    def save_original(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        og_path = out_path / f\"{audio_path.parent.stem}_{audio_path.name}\"\n",
        "        self.write_to_transcript(og_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        torchaudio.save(uri = og_path, src = audio, sample_rate = sample_rate)\n",
        "\n",
        "    def save_pitch_shifted(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        ps_path = out_path / f\"{audio_path.parent.stem}_ps_{audio_path.name}\"\n",
        "        self.write_to_transcript(ps_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        pitch_shifted_audio = self.augmentor.shift_pitch(audio, sample_rate)\n",
        "        torchaudio.save(uri= ps_path, src = pitch_shifted_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_noisy(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, snr: int, label: str, out_transcr_file: IO) -> None:\n",
        "        n_path = out_path / f\"{audio_path.parent.stem}_n_{audio_path.name}\"\n",
        "        self.write_to_transcript(n_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        noisy_audio = self.augmentor.add_background_crowd(audio, snr = snr)\n",
        "        torchaudio.save(uri= n_path, src = noisy_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_white_noisy(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, snr: int, variance: int,  label: str, out_transcr_file: IO) -> None:\n",
        "        wn_path = out_path / f\"{audio_path.parent.stem}_wn_{audio_path.name}\"\n",
        "        self.write_to_transcript(wn_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        white_noisy_audio = self.augmentor.add_white_noise(audio, snr = snr, variance = variance)\n",
        "        torchaudio.save(uri= wn_path, src = white_noisy_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_room_reverbed(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        rr_path = out_path / f\"{audio_path.parent.stem}_rr_{audio_path.name}\"\n",
        "        self.write_to_transcript(rr_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        room_reverbed_audio = self.augmentor.add_room_reverb(audio)\n",
        "        torchaudio.save(uri= rr_path, src = room_reverbed_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_speed_perturbed(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        sp_path = out_path / f\"{audio_path.parent.stem}_sp_{audio_path.name}\"\n",
        "        self.write_to_transcript(sp_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        speed_perturbed_audio = self.augmentor.perturb_speed(audio, sample_rate, factors = [0.9, 0.95, 1.05, 1.1])\n",
        "        torchaudio.save(uri= sp_path, src = speed_perturbed_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_low_passed(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        lpf_path = out_path / f\"{audio_path.parent.stem}_lpf_{audio_path.name}\"\n",
        "        low_passed_audio = self.augmentor.apply_low_pass_filter(audio, sample_rate)\n",
        "        self.write_to_transcript(lpf_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        torchaudio.save(uri= lpf_path, src = low_passed_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def write_transcript_headers(self)->None:\n",
        "        header_1, header_2 = TranslitDict.DEFAULT_HEADERS\n",
        "        out_transcr_file.write(f\"{header_1}\\t{header_2}\")\n",
        "\n",
        "\n",
        "    def preprocess(self) -> None:\n",
        "        if self.augmentor and self.resample_rate:\n",
        "            self.augmentor.resample_assets(self.resample_rate)\n",
        "\n",
        "        self.out_folder.mkdir()\n",
        "\n",
        "        out_transcr_path = self.out_folder / Path(self.out_transcr_name)\n",
        "        with open(out_transcr_path, mode = 'w', encoding = 'utf-8') as out_transcr_file:\n",
        "            self.preprocess_dir(self.data_folder, out_transcr_file)\n",
        "\n",
        "    def preprocess_dir(self, folder: Path, out_transcr_file: IO) -> None:\n",
        "        # If there are nested folders go inside and handle separately as a unit (of transcript file and audio files)\n",
        "        for path in folder.iterdir():\n",
        "            if self.skip and path.name in self.skip: #directory to be skipped\n",
        "                continue\n",
        "\n",
        "            if path.is_dir():\n",
        "                self.preprocess_dir(path, out_transcr_file)\n",
        "                continue\n",
        "\n",
        "        # the presence of a transcript file tells us that this is a concerned directory (an audio-transcript unit)\n",
        "        audio_label_dict = self.get_audio_label_dict(folder)\n",
        "\n",
        "        if not audio_label_dict:\n",
        "            return\n",
        "\n",
        "        out_path = self.out_folder\n",
        "        #self.write_transcript_headers()\n",
        "        for audio_path in audio_label_dict.keys():\n",
        "\n",
        "            label = audio_label_dict[audio_path]\n",
        "            audio, sample_rate = torchaudio.load(audio_path)\n",
        "\n",
        "            if not self.augmentor:\n",
        "                continue\n",
        "\n",
        "            if self.mono:\n",
        "                audio = self.augmentor.convert_to_mono(audio)\n",
        "\n",
        "            if self.resample_rate:\n",
        "                audio = self.augmentor.resample(audio, sample_rate, self.resample_rate)\n",
        "                sample_rate = self.resample_rate\n",
        "\n",
        "            self.save_original(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "\n",
        "            if not self.augment:\n",
        "                continue\n",
        "\n",
        "            self.save_pitch_shifted(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "            self.save_noisy(audio_path, out_path, audio, sample_rate, 20, label, out_transcr_file)\n",
        "            self.save_white_noisy(audio_path, out_path, audio, sample_rate, 20, 0.01, label, out_transcr_file)\n",
        "            self.save_room_reverbed(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "            self.save_speed_perturbed(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "            self.save_low_passed(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N2tCI-OSVZNm",
        "outputId": "04cdcc8b-fdcb-4132-d5ec-8e4933f2aa9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:71: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:71: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-2336241896.py:71: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  spaces = '\\s'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##COPY TEST FOLDER AND RUN TESTS"
      ],
      "metadata": {
        "id": "tJT7ajzzOUVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CS MANUAL DATASET"
      ],
      "metadata": {
        "id": "TaN8mfo9_j7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/data\n",
        "!mkdir /content/data"
      ],
      "metadata": {
        "id": "nYsGIFi0h_87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52dffda1-6d3d-40a8-bbe7-2f14764cc801"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/data': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud96TvgfCS5x",
        "outputId": "c9eebe93-1b70-45c1-9c64-81513fd9708d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Doers_1\t\t\t\t      SS_Dr_Dilip_Sharma\n",
            " Doers_Accidental_Banker\t\t      SS_Dr_Gehendra_Purush_Dhakal\n",
            " Doers_Hivelaya\t\t\t\t      SS_Dr_Gehendra_Purush_Dhakal_2\n",
            " Doers_Pahadi_Foods_Prashant_Ghimire_1\t      SS_Dr_Jaya\n",
            " Doers_Pahadi_Foods_Prashant_Ghimire_2\t      SS_Dr_Sanjay_Sharma\n",
            " Doers_Prasanna_Dhungel_Market_Intelligence   SS_Dr_Sanjay_Sharma_2\n",
            " Doers_Prof_Samrachana\t\t\t     'SS_Mahabir Paudyal'\n",
            " PP_Iih\t\t\t\t\t      SS_Munu_Adhikari\n",
            " PP_Swarnim_Wagle\t\t\t      SS_Pradip_Raj_Giri\n",
            " PP_Swarnim_Wagle_2\t\t\t      SS_Rupeshwor_Gaur_Das\n",
            " SG_Palesha_Goverdhan\t\t\t      SS_Sanjog_Koirala\n",
            " SG_Palesha_Goverdhan_2\t\t\t      SS_Sanjog_Koirala_2\n",
            " SG_Uniq_Poet\t\t\t\t      SS_Siddhant_Acharya\n",
            " SS_Amod_Nath_Pyakuryal\t\t\t      SS_Skanda_Gautam\n",
            " SS_Asheem_Basnyat\t\t\t      SS_Sudheer_Sharma\n",
            " SS_Bibhusan_Bista\t\t\t      SS_Sudheer_Sharma_2\n",
            " SS_Chanira_Bajracharya\t\t\t      SS_Suresh_Bhattarai\n",
            " SS_Chiran_Jung_Thapa\t\t\t      SS_Suresh_Dhakal\n",
            " SS_Dipak_Gyawali\t\t\t     'Transliteration Dictionary'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/* /content/data/\n",
        "# %cd /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/\n",
        "# !cp -r SG_Uniq_Poet SG_Palesha_Goverdhan SS_Dr_Jaya /content/data/\n",
        "# %cd ~"
      ],
      "metadata": {
        "id": "yoXMSml0CLZS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/Transliteration Dictionary/Roman_Devanagari_Translit_Dict.json' /content/"
      ],
      "metadata": {
        "id": "fblh_fOkslmV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translitr = RomanToDevaTransliterator(translit_dict='/content/Roman_Devanagari_Translit_Dict.json')"
      ],
      "metadata": {
        "id": "kTOsBFmHy8BQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4619de4e-9f37-4eec-fb65-eef23302ef17"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/data_out"
      ],
      "metadata": {
        "id": "T-3hIjUoOerC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####AUGMENT AND TRANSLITERATE"
      ],
      "metadata": {
        "id": "QBos7DX_UN7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", transliterator = translitr, augmentor = AudioAugmentor(), augment = True)\n",
        "preprocessor.preprocess(); #To include extensions in file ids in transcript file see method write_to_transcript(). Perhaps this feature should be included as an attribute in AudioPreprocessor class.\n"
      ],
      "metadata": {
        "id": "JonvutPqy5Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####WRITE TRANSCRIPTS IN PROPER FORMAT WITHOUT TRANSLITERATION (AUDIO_ID TRANSCRIPT)"
      ],
      "metadata": {
        "id": "Y0Z1k6hbUWlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", augmentor = AudioAugmentor(), save_aud=False)\n",
        "preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "Sq4B48JbUZJj",
        "outputId": "eea96ea2-5c09-4c4c-ce31-0af28375a6ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3542478349.py:9: UserWarning: torchaudio.utils.download.download_asset has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  rir_loc = torchaudio.utils.download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo-8000hz.wav\")\n",
            "/tmp/ipython-input-3542478349.py:10: UserWarning: torchaudio.utils.download.download_asset has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  noise_loc = torchaudio.utils.download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo-8000hz.wav\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####TRANSLITERATE BUT DON'T TOUCH AUDIO"
      ],
      "metadata": {
        "id": "NCIOQqFbUm9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", transliterator = translitr, save_aud=False)\n",
        "preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "WOqmQvdzUrqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####SAVE TO DRIVE"
      ],
      "metadata": {
        "id": "MMD5haK3U-Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/data_out.zip /content/data_out\n",
        "!cp /content/data_out.zip /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual_Augmented.zip"
      ],
      "metadata": {
        "id": "e04EBIGuhA4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BHATTA DATASET RESAMPLING, CONVERSION TO MONO"
      ],
      "metadata": {
        "id": "OmGuJ8ZU6KQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/Bhatta_Normalized_DataSet/\n",
        "!mkdir --parents /content/Bhatta_Normalized_DataSet/bharat1/ /content/Bhatta_Normalized_DataSet/ganNeshsir3/"
      ],
      "metadata": {
        "id": "5sa96wFrxZJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/MSICE/Pure_Nepali_Labelled_Speech_Data/Dataset/Train/SECTEC /content/"
      ],
      "metadata": {
        "id": "Ftxs1uhRdfNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/SECTEC"
      ],
      "metadata": {
        "id": "RSBXfUwDdonB",
        "outputId": "6a242e05-d96a-4893-bc7d-acc3cccf3e4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "dr-x------ 2 root root 4096 Sep  6 11:27 bharat1\n",
            "dr-x------ 2 root root 4096 Sep  6 11:27 ganNeshsir3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def normalize_bhatta_dataset(data_fol:str, out_fol:str, mono: bool, new_sample_rate: int) -> None:\n",
        "    data_fol = Path(data_fol)\n",
        "    out_fol = Path(out_fol)\n",
        "\n",
        "    #AUDIO\n",
        "    audio_ext_pattern = re.compile(r\"\\.wav$\")\n",
        "    aug = AudioAugmentor()\n",
        "    for path in data_fol.iterdir():\n",
        "        if not path.is_file() or not audio_ext_pattern.search(path.name):\n",
        "            continue\n",
        "        audio, sample_rate = torchaudio.load(path)\n",
        "        if mono:\n",
        "            audio = aug.convert_to_mono(audio_tensor = audio)\n",
        "        if new_sample_rate:\n",
        "            sample_rate = new_sample_rate\n",
        "        torchaudio.save(uri = f\"{out_fol}/{path.name}\", src = audio, sample_rate=sample_rate)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ba1DR7a7yD5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize_bhatta_dataset(data_fol = \"/content/SECTEC/bharat1\", out_fol = \"/content/Bhatta_Normalized_DataSet/bharat1/\", mono = True, new_sample_rate = 16000)\n",
        "!cp /content/SECTEC/bharat1/SECTEC_bharat1.trans.txt /content/Bhatta_Normalized_DataSet/bharat1/"
      ],
      "metadata": {
        "id": "A9m7RqjI28dN",
        "outputId": "d9b7ab8e-b3e8-4363-8a63-e1a490e25081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3542478349.py:9: UserWarning: torchaudio.utils.download.download_asset has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  rir_loc = torchaudio.utils.download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo-8000hz.wav\")\n",
            "/tmp/ipython-input-3542478349.py:10: UserWarning: torchaudio.utils.download.download_asset has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  noise_loc = torchaudio.utils.download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo-8000hz.wav\")\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:247: UserWarning: torio.io._streaming_media_encoder.StreamingMediaEncoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamWriter(uri, format=muxer, buffer_size=buffer_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/Bhatta_Normalized_DataSet/bharat1/SECTEC_bharat1.trans.txt | wc -l\n",
        "!ls /content/Bhatta_Normalized_DataSet/bharat1/ | grep 'wav' | wc -l"
      ],
      "metadata": {
        "id": "F84yjvRY3r5L",
        "outputId": "c77aba24-9130-4503-dfbf-21d65e85ab67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalize_bhatta_dataset(data_fol = \"/content/SECTEC/ganNeshsir3\", out_fol = \"/content/Bhatta_Normalized_DataSet/ganNeshsir3\", mono = True, new_sample_rate = 16000)\n",
        "!cp /content/SECTEC/ganNeshsir3/SECTEC_ganNeshsir3.trans.txt /content/Bhatta_Normalized_DataSet/ganNeshsir3/"
      ],
      "metadata": {
        "id": "zNqui4cw4XUK",
        "outputId": "e9e94655-5d31-4646-cf1f-1c224457f2e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3542478349.py:9: UserWarning: torchaudio.utils.download.download_asset has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  rir_loc = torchaudio.utils.download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo-8000hz.wav\")\n",
            "/tmp/ipython-input-3542478349.py:10: UserWarning: torchaudio.utils.download.download_asset has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  noise_loc = torchaudio.utils.download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo-8000hz.wav\")\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:247: UserWarning: torio.io._streaming_media_encoder.StreamingMediaEncoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamWriter(uri, format=muxer, buffer_size=buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/SECTEC/bharat1/SECTEC_ganNeshsir3.trans.txt': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/Bhatta_Normalized_DataSet/ganNeshsir3/SECTEC_ganNeshsir3.trans.txt | wc -l\n",
        "!ls /content/Bhatta_Normalized_DataSet/ganNeshsir3/ | grep 'wav' | wc -l"
      ],
      "metadata": {
        "id": "2Z4HlWdy6Ni0",
        "outputId": "a9808867-78eb-4a45-e53a-7cd14400d7de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp Bhatta_Normalized_DataSet.zip /content/drive/MyDrive/MSICE/"
      ],
      "metadata": {
        "id": "ZZMB-S6M6933"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/drive/MyDrive/MSICE"
      ],
      "metadata": {
        "id": "CRg6-hiE7L1-",
        "outputId": "77b7c342-2f07-41d0-9241-ef01dc0f74f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 531524\n",
            "-rw------- 1 root root 155996529 Sep 23  2024 '074BCT audio dataset-20240923T044153Z-001.zip'\n",
            "drwx------ 2 root root      4096 Dec  7  2024  Articles\n",
            "-rw------- 1 root root  96846716 Sep  6 12:07  Bhatta_Normalized_DataSet.zip\n",
            "drwx------ 2 root root      4096 Aug 11 09:23 'Dependency Corrections'\n",
            "drwx------ 2 root root      4096 Jun 23 05:57  English_Nepali_CS_Data_Manual\n",
            "-rw------- 1 root root  81637102 Sep  6 08:19  English_Nepali_CS_Data_Manual_Augmented_WO_ext.zip\n",
            "-rw------- 1 root root  81637876 Sep  6 08:19  English_Nepali_CS_Data_Manual_Augmented.zip\n",
            "drwx------ 2 root root      4096 Dec  4  2024 'English To Nepali Transliteration Dictionary'\n",
            "drwx------ 2 root root      4096 Oct 14  2024 'Óbuda University '\n",
            "drwx------ 2 root root      4096 Jan 30  2025  Predetermined_CS_Texts\n",
            "drwx------ 2 root root      4096 Jun 23 05:59  Pure_Nepali_Labelled_Speech_Data\n",
            "-rw------- 1 root root 128120317 Jun 23 14:49  real_time_test-20240823T071018Z-001.zip\n",
            "drwx------ 2 root root      4096 Feb  7  2024 'SEM II'\n",
            "drwx------ 2 root root      4096 Mar 27  2024 'SEM III'\n",
            "drwx------ 2 root root      4096 Dec  7  2024 'SEMS III & IV'\n"
          ]
        }
      ]
    }
  ]
}