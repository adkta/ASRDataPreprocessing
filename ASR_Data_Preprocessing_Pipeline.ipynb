{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRfFccobzu8rHD4CIXG1gS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##DESIGN\n",
        "\"\"\"\n",
        "Preprocessing\n",
        "\n",
        "  Convert To Mono\n",
        "  Audio Enhancement (optional)\n",
        "  Label transliteration\n",
        "  Remove punctuation\n",
        "  Augmentation\n",
        "  Label copying\n",
        "  Necessary folder arrangement to load data and feed into wav2vec2\n",
        "\n",
        "\n",
        "Data\n",
        "  Folder1\n",
        "    audio_1\n",
        "    audio_2\n",
        "    ...\n",
        "    transcript    \n",
        "  Folder2\n",
        "    audio_1\n",
        "    audio_2\n",
        "    ...\n",
        "    transcript\n",
        "  ...\n",
        "\n",
        "DataFolderPath\n",
        "->\n",
        "Preprocessor\n",
        "(walks data folder)\n",
        "searches for transcript file, finds file and creates transliterated transcript file/ generates a pandas transliterated row for the file.\n",
        "Each audio is augmented (list of augmentation is provided) corresponding label\n",
        "->\n",
        "Transliteration using dictionary\n",
        "->\n",
        "Augmentation\n",
        "->\n",
        "Label Copy\n",
        "->\n",
        "Folder format\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "D8gy1vonp0l0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SETUP"
      ],
      "metadata": {
        "id": "FX0PnyeYNp8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchcodec"
      ],
      "metadata": {
        "id": "hbpXmZwGn8aY",
        "outputId": "5aa65068-c0f6-4186-a9ec-9c8ed687c978",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchcodec\n",
            "  Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchcodec\n",
            "Successfully installed torchcodec-0.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install g2p_en"
      ],
      "metadata": {
        "id": "h-CF91aBswAD",
        "outputId": "8b66ef62-d74f-40c7-adce-39bbbbc5fe5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting g2p_en\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.12/dist-packages (from g2p_en) (2.0.2)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.12/dist-packages (from g2p_en) (3.9.1)\n",
            "Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from g2p_en) (7.5.0)\n",
            "Collecting distance>=0.1.3 (from g2p_en)\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.12/dist-packages (from inflect>=0.3.1->g2p_en) (10.8.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from inflect>=0.3.1->g2p_en) (4.4.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.4->g2p_en) (4.67.1)\n",
            "Requirement already satisfied: typing_extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from typeguard>=4.0.1->inflect>=0.3.1->g2p_en) (4.15.0)\n",
            "Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: distance\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16256 sha256=bcd026a80fc635d2bfa601020f287771eb82a154b536975db54b9d8f8abed552\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/a8/58/407063d8e5c1d4dd6594c99d12baa0108570b56a92325587dd\n",
            "Successfully built distance\n",
            "Installing collected packages: distance, g2p_en\n",
            "Successfully installed distance-0.1.3 g2p_en-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dXhHz3vIi_CG",
        "outputId": "d0bc33d8-b8e7-4156-8cce-79a475b14756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nepali-num2word"
      ],
      "metadata": {
        "id": "9Z2VtVzukhG0",
        "outputId": "64635a93-26e8-4a0a-9e3c-311dd8d068d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nepali-num2word\n",
            "  Downloading nepali_num2word-0.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading nepali_num2word-0.2.3-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: nepali-num2word\n",
            "Successfully installed nepali-num2word-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/adkta/nepali_arabic_num_to_word.git"
      ],
      "metadata": {
        "id": "9ny6pYyZkh5U",
        "outputId": "af1b1368-a107-40db-ceab-edcf7d3fafbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nepali_arabic_num_to_word'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 18 (delta 5), reused 7 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (18/18), 4.97 KiB | 1.24 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/transliteration"
      ],
      "metadata": {
        "id": "phuzjpfuM1WS",
        "outputId": "cec27c56-6460-4a34-a3ec-350fade3e793",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/transliteration': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/adkta/transliteration.git"
      ],
      "metadata": {
        "id": "W3H9FIY5pBet",
        "outputId": "10e466ef-f873-493f-c6ef-109de8db864e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transliteration'...\n",
            "remote: Enumerating objects: 224, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 224 (delta 0), reused 0 (delta 0), pack-reused 221 (from 1)\u001b[K\n",
            "Receiving objects: 100% (224/224), 52.98 KiB | 3.53 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.path)"
      ],
      "metadata": {
        "id": "jBWr2FVIullx",
        "outputId": "c569e401-4ce5-4346-93ad-ca17ff997d8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.12/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from typing import Union, Optional\n",
        "from pathlib import Path\n",
        "from transliteration.transliterator import Transliterator\n",
        "from transliteration.transliterators import RomanToDevaTransliterator\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections.abc import Generator"
      ],
      "metadata": {
        "id": "yegl7DcSVXKs",
        "outputId": "14329f0c-7a8a-4323-b2d0-3403ed041bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/transliteration/transliterator.py:123: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  label.strip('\\s,\"?.|')\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transliteration.transliterator import TranslitDict"
      ],
      "metadata": {
        "id": "ONGdQx675b2e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LOGGING CONFIGURATION"
      ],
      "metadata": {
        "id": "WzAjhysBdPt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "LOG_LEVEL = logging.INFO\n",
        "_log_path = '/content/preprocessing.log'\n",
        "logger = logging.getLogger(\"preprocessing\")\n",
        "logger.setLevel(LOG_LEVEL)\n",
        "_handler = logging.FileHandler(_log_path)\n",
        "_handler.setLevel(LOG_LEVEL)\n",
        "_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
        "logger.addHandler(_handler)"
      ],
      "metadata": {
        "id": "YIiuVD4X6FMa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PREPROCESSING CLASSES"
      ],
      "metadata": {
        "id": "Kyk5CNuBQ_WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Utils:\n",
        "    @staticmethod\n",
        "    def get_matching_files(data_fol: Path, file_pattern: str) -> Generator[Path, None, None]:\n",
        "        file_pattern = re.compile(file_pattern)\n",
        "        for f in data_fol.iterdir():\n",
        "            if file_pattern.search(f.as_posix()):\n",
        "                yield f"
      ],
      "metadata": {
        "id": "mcA-IIERLZy4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "onbtow9TtXMo"
      },
      "outputs": [],
      "source": [
        "import torchaudio\n",
        "import torch\n",
        "\n",
        "class AudioAugmentor:\n",
        "    def __init__(self) -> None:\n",
        "        self.download_assets()\n",
        "\n",
        "    def download_assets(self) -> None:\n",
        "        rir_loc = torchaudio.utils._download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo-8000hz.wav\")\n",
        "        noise_loc = torchaudio.utils._download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo-8000hz.wav\")\n",
        "        self.rir, self.rir_sample_rate = torchaudio.load(rir_loc)\n",
        "        self.noise, self.noise_sample_rate = torchaudio.load(noise_loc)\n",
        "        self.noise = self.noise/torch.linalg.vector_norm(self.noise)\n",
        "\n",
        "    def resample_assets(self, new_sample_rate: int) -> None:\n",
        "        self.rir = torchaudio.transforms.Resample(orig_freq=self.rir_sample_rate, new_freq=new_sample_rate)(self.rir)\n",
        "        self.noise = torchaudio.transforms.Resample(orig_freq=self.noise_sample_rate, new_freq=new_sample_rate)(self.noise)\n",
        "\n",
        "    def frame_count(self, waveform: torch.Tensor) -> int:\n",
        "        return waveform.shape[1]\n",
        "\n",
        "    def adjust_noise_frame_count_for_add(self, waveform: torch.Tensor, noise: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Noise adjustment for addition to signal\n",
        "        \"\"\"\n",
        "        noise_frame_count = self.frame_count(noise)\n",
        "        signal_frame_count = self.frame_count(waveform)\n",
        "        if noise_frame_count == signal_frame_count:\n",
        "            pass\n",
        "        elif noise_frame_count > signal_frame_count:\n",
        "            noise = noise[:, :signal_frame_count]\n",
        "        else:\n",
        "            quo, rem= divmod(signal_frame_count, noise_frame_count)\n",
        "            repeated_noise_list=[]\n",
        "            for _ in range(quo):\n",
        "                repeated_noise_list.append(noise)\n",
        "            repeated_noise_list.append(noise[:, :rem])\n",
        "            noise = torch.cat(repeated_noise_list, dim = 1)\n",
        "        return noise\n",
        "\n",
        "    def validate_audio_data(self, audio_data: Union[str, Path, torch.Tensor]) -> torch.Tensor:\n",
        "        assert audio_data.is_file(), \"audio_data must be a torch.Tensor, str path to an audio file or Path object to an audio file\"\n",
        "\n",
        "    def convert_to_mono(self, audio_tensor: torch.Tensor) -> torch.Tensor:\n",
        "        if audio_tensor.shape[0] == 1:\n",
        "            return audio_tensor\n",
        "        return torch.mean(audio_tensor, dim=0, keepdim=True)\n",
        "\n",
        "    def resample(self, waveform: torch.Tensor, orig_sample_rate: int, new_sample_rate: int) -> torch.Tensor:\n",
        "        return torchaudio.transforms.Resample(orig_freq=orig_sample_rate, new_freq=new_sample_rate)(waveform)\n",
        "\n",
        "    def shift_pitch(self, audio_data: torch.Tensor, sample_rate: int) -> torch.Tensor:\n",
        "        return torchaudio.transforms.PitchShift(sample_rate = sample_rate, n_steps = 2)(audio_data)\n",
        "\n",
        "    def add_background_crowd(self, audio_data: torch.Tensor, snr: int) -> torch.Tensor:\n",
        "        adj_resampled_noise = self.adjust_noise_frame_count_for_add(waveform = audio_data, noise = self.noise)\n",
        "        add_noise = torchaudio.transforms.AddNoise()\n",
        "        noisy_audio = add_noise(waveform = audio_data, noise = adj_resampled_noise, snr = torch.tensor([snr]))\n",
        "        return noisy_audio\n",
        "\n",
        "    def add_white_noise(self, audio_data: torch.Tensor, snr: int, variance: int) -> torch.Tensor:\n",
        "        white_noise = torch.randn_like(audio_data) * variance\n",
        "        white_noisy_audio = torchaudio.functional.add_noise(audio_data, white_noise,snr=torch.tensor([snr]))\n",
        "        return white_noisy_audio\n",
        "\n",
        "    def add_room_reverb(self, audio_data: torch.Tensor) -> torch.Tensor:\n",
        "        return torchaudio.functional.fftconvolve(audio_data, self.rir)\n",
        "\n",
        "    def perturb_speed(self, audio_data: torch.Tensor, sample_rate: int, factors: list[float]) -> torch.Tensor:\n",
        "        speed_perturb = torchaudio.transforms.SpeedPerturbation(orig_freq= sample_rate, factors = factors)\n",
        "        perturbed_audio, _ = speed_perturb(waveform = audio_data)\n",
        "        return perturbed_audio\n",
        "\n",
        "    def apply_low_pass_filter(self, audio_data: torch.Tensor, sample_rate: int) -> torch.Tensor:\n",
        "        req_effect = \"lowpass=frequency=1000\"\n",
        "        effector = torchaudio.io.AudioEffector(effect=req_effect)\n",
        "        filtered_audio_list = []\n",
        "        for chunk in effector.stream(waveform=audio_data.T, sample_rate = sample_rate, frames_per_chunk = 48000):\n",
        "            filtered_audio_list.append(chunk)\n",
        "        filtered_audio = torch.cat(filtered_audio_list, dim=0).T\n",
        "        return filtered_audio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import IO\n",
        "from transliteration.transliterator import Transliterator\n",
        "\n",
        "\n",
        "class AudioPreprocessor:\n",
        "    \"\"\"\n",
        "    Audio identifiers in the transcript file will only be searched non-recursively in the folder housing the transcript file.\n",
        "    Currently the preprocessor expects the following format in the transcript file.\n",
        "    Each line corresponds to audio_<audio_number>.<audio_ext>. Eg. line 1 would be for audio_1.mp3, line 2 for audio_2.mp3 and so on.\n",
        "    A future to do may process the file in format: audio_id<delimiter>label (which is the output format)\n",
        "    \"\"\"\n",
        "\n",
        "    audio_ext_pattern = r\"\\.mp3$|\\.wav$|\\.opus$\"\n",
        "    DEFAULT_RESAMPLE_RATE = 16000\n",
        "    TKNZR_PATTERN = re.compile(TranslitDict.PUNCT_SPACE_REGEX)\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_folder: str,\n",
        "        out_folder: str,\n",
        "        skip: Union[tuple[str],None] = None,\n",
        "        transcr_name:tuple[str] = (\"transcript.txt\",),\n",
        "        out_transcr_name: str = \"transcript.txt\",\n",
        "        transliterator: Optional[Transliterator] = None,\n",
        "        save_aud: bool = True,\n",
        "        augmentor: Optional[AudioAugmentor] = None,\n",
        "        mono: bool = True,\n",
        "        resample_rate: Optional[int] = DEFAULT_RESAMPLE_RATE,\n",
        "        augment: bool = False\n",
        "        ) -> None:\n",
        "        \"\"\"\n",
        "        :param data_folder: str Input data folder\n",
        "        :param out_folder: str Output folder\n",
        "        :param skip: Union[tuple[str], None] List of files/folders to skip\n",
        "        :param transcr_name: str List of names that qualify as transcript files\n",
        "        :param transliterator: Optional[Transliterator] Transliterator to use. If not specified will not transliterate labels\n",
        "        :param augmentor: Augmentor Augmentor to use. If not specified, will not augment the audio\n",
        "        :param mono: bool Convert to mono channel\n",
        "        :param resample_rate: int Resample rate\n",
        "        \"\"\"\n",
        "        self.data_folder = Path(data_folder)\n",
        "        self.out_folder = Path(out_folder)\n",
        "        self.skip = skip\n",
        "        self.transcr_name = transcr_name\n",
        "        self.out_transcr_name = out_transcr_name\n",
        "        self.transliterator = transliterator\n",
        "        self.save_aud = save_aud\n",
        "        self.augmentor = augmentor\n",
        "        self.mono = mono\n",
        "        self.resample_rate = resample_rate\n",
        "        self.augment = augment\n",
        "\n",
        "    def is_audio(self, path: Path) -> bool:\n",
        "        return path.is_file() and path.name.endswith(AudioPreprocessor.audio_ext)\n",
        "\n",
        "    def get_transcr_file(self, folder: Path) -> Optional[Path]:\n",
        "        transcript_files = []\n",
        "        for fn in self.transcr_name:\n",
        "            logger.info(f\"Searching for {fn} in {folder}\")\n",
        "            if transcript_file := list(folder.glob(fn)):\n",
        "                transcript_files.extend(transcript_file)\n",
        "\n",
        "        assert len(transcript_files) < 2, \"More than one transcript file\"\n",
        "        return transcript_files[0] if transcript_files else None\n",
        "\n",
        "    def get_audio_files(self, folder: Path) -> Generator[Path, None, None]:\n",
        "        return Utils.get_matching_files(data_fol = folder, file_pattern = AudioPreprocessor.audio_ext_pattern)\n",
        "\n",
        "    def get_transcripts(self, transcript_file: Path) -> Generator[str, None, None]:\n",
        "        with open(transcript_file, 'r') as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                  continue\n",
        "                if self.transliterator:\n",
        "                  line = self.transliterate_line(line)\n",
        "                yield line\n",
        "\n",
        "    def transliterate_line(self, line: str) -> str:\n",
        "        words = AudioPreprocessor.TKNZR_PATTERN.split(line)\n",
        "        tl_words = []\n",
        "        for word in words:\n",
        "            if self.transliterator.for_transliteration(word):\n",
        "                word = self.transliterator.translit(word)\n",
        "            tl_words.append(word)\n",
        "        return \" \".join(tl_words)\n",
        "\n",
        "    def get_audio_label_dict(self, folder: Path) -> Optional[dict[Path, str]]:\n",
        "        transcript_file = self.get_transcr_file(folder)\n",
        "        if not transcript_file:\n",
        "            return None\n",
        "        numbered_audio_filter = lambda x: len(x.stem.split('_')) == 2\n",
        "        audio_num = lambda x: int(x.stem.split('_')[1])\n",
        "        sorted_audio_path: list[Path] = sorted(filter(numbered_audio_filter, self.get_audio_files(folder)), key = audio_num)\n",
        "        transcripts: Generator[str, None, None] = self.get_transcripts(transcript_file)\n",
        "        audio_label_dict:dict[Path, str] = dict(zip(sorted_audio_path, transcripts))\n",
        "        return audio_label_dict\n",
        "\n",
        "    def write_to_transcript(self, audio_path: Path, label: str, out_transcr_file: IO, ext: bool = False) -> None:\n",
        "        audio_id = audio_path.stem #additional assignment for code readability. Con: requires 2 assignment statements if ext = True.\n",
        "        if ext:\n",
        "            audio_id = audio_path.name\n",
        "        logger.debug(f\"Writing to {out_transcr_file}\")\n",
        "        out_transcr_file.write(f\"{audio_id}\\t{label}\\n\")\n",
        "\n",
        "    def save_original(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        og_path = out_path / f\"{audio_path.parent.stem}_{audio_path.name}\"\n",
        "        self.write_to_transcript(og_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        torchaudio.save(uri = og_path, src = audio, sample_rate = sample_rate)\n",
        "\n",
        "    def save_pitch_shifted(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        ps_path = out_path / f\"{audio_path.parent.stem}_ps_{audio_path.name}\"\n",
        "        self.write_to_transcript(ps_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        pitch_shifted_audio = self.augmentor.shift_pitch(audio, sample_rate)\n",
        "        torchaudio.save(uri= ps_path, src = pitch_shifted_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_noisy(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, snr: int, label: str, out_transcr_file: IO) -> None:\n",
        "        n_path = out_path / f\"{audio_path.parent.stem}_n_{audio_path.name}\"\n",
        "        self.write_to_transcript(n_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        noisy_audio = self.augmentor.add_background_crowd(audio, snr = snr)\n",
        "        torchaudio.save(uri= n_path, src = noisy_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_white_noisy(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, snr: int, variance: int,  label: str, out_transcr_file: IO) -> None:\n",
        "        wn_path = out_path / f\"{audio_path.parent.stem}_wn_{audio_path.name}\"\n",
        "        self.write_to_transcript(wn_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        white_noisy_audio = self.augmentor.add_white_noise(audio, snr = snr, variance = variance)\n",
        "        torchaudio.save(uri= wn_path, src = white_noisy_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_room_reverbed(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        rr_path = out_path / f\"{audio_path.parent.stem}_rr_{audio_path.name}\"\n",
        "        self.write_to_transcript(rr_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        room_reverbed_audio = self.augmentor.add_room_reverb(audio)\n",
        "        torchaudio.save(uri= rr_path, src = room_reverbed_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_speed_perturbed(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        sp_path = out_path / f\"{audio_path.parent.stem}_sp_{audio_path.name}\"\n",
        "        self.write_to_transcript(sp_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        speed_perturbed_audio = self.augmentor.perturb_speed(audio, sample_rate, factors = [0.9, 0.95, 1.05, 1.1])\n",
        "        torchaudio.save(uri= sp_path, src = speed_perturbed_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_low_passed(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        lpf_path = out_path / f\"{audio_path.parent.stem}_lpf_{audio_path.name}\"\n",
        "        low_passed_audio = self.augmentor.apply_low_pass_filter(audio, sample_rate)\n",
        "        self.write_to_transcript(lpf_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        torchaudio.save(uri= lpf_path, src = low_passed_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def write_transcript_headers(self)->None:\n",
        "        header_1, header_2 = TranslitDict.DEFAULT_HEADERS\n",
        "        out_transcr_file.write(f\"{header_1}\\t{header_2}\\n\")\n",
        "\n",
        "\n",
        "    def preprocess(self) -> None:\n",
        "        if self.augmentor and self.resample_rate:\n",
        "            self.augmentor.resample_assets(self.resample_rate)\n",
        "\n",
        "        self.out_folder.mkdir()\n",
        "\n",
        "        out_transcr_path = self.out_folder / Path(self.out_transcr_name)\n",
        "        with open(out_transcr_path, mode = 'w', encoding = 'utf-8') as out_transcr_file:\n",
        "            self.preprocess_dir(self.data_folder, out_transcr_file)\n",
        "\n",
        "    def preprocess_dir(self, folder: Path, out_transcr_file: IO) -> None:\n",
        "        # If there are nested folders go inside and handle separately as a unit (of transcript file and audio files)\n",
        "        for path in folder.iterdir():\n",
        "            if self.skip and path.name in self.skip: #directory to be skipped\n",
        "                continue\n",
        "\n",
        "            if path.is_dir():\n",
        "                self.preprocess_dir(path, out_transcr_file)\n",
        "                continue\n",
        "\n",
        "        # the presence of a transcript file tells us that this is a concerned directory (an audio-transcript unit)\n",
        "        audio_label_dict = self.get_audio_label_dict(folder)\n",
        "\n",
        "        if not audio_label_dict:\n",
        "            return\n",
        "\n",
        "        out_path = self.out_folder\n",
        "        #self.write_transcript_headers()\n",
        "        for audio_path in audio_label_dict.keys():\n",
        "\n",
        "            label = audio_label_dict[audio_path]\n",
        "            audio, sample_rate = torchaudio.load(audio_path)\n",
        "\n",
        "            if not self.augmentor:\n",
        "                continue\n",
        "\n",
        "            if self.mono:\n",
        "                audio = self.augmentor.convert_to_mono(audio)\n",
        "\n",
        "            if self.resample_rate:\n",
        "                audio = self.augmentor.resample(audio, sample_rate, self.resample_rate)\n",
        "                sample_rate = self.resample_rate\n",
        "\n",
        "            self.save_original(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "\n",
        "            if not self.augment:\n",
        "                continue\n",
        "\n",
        "            self.save_pitch_shifted(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "            self.save_noisy(audio_path, out_path, audio, sample_rate, 20, label, out_transcr_file)\n",
        "            self.save_white_noisy(audio_path, out_path, audio, sample_rate, 20, 0.01, label, out_transcr_file)\n",
        "            self.save_room_reverbed(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "            self.save_speed_perturbed(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "            self.save_low_passed(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N2tCI-OSVZNm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##COPY TEST FOLDER AND RUN TESTS"
      ],
      "metadata": {
        "id": "tJT7ajzzOUVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CS MANUAL DATASET"
      ],
      "metadata": {
        "id": "TaN8mfo9_j7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/data\n",
        "!mkdir /content/data"
      ],
      "metadata": {
        "id": "nYsGIFi0h_87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/"
      ],
      "metadata": {
        "id": "Ud96TvgfCS5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/* /content/data/\n",
        "# %cd /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/\n",
        "# !cp -r SG_Uniq_Poet SG_Palesha_Goverdhan SS_Dr_Jaya /content/data/\n",
        "# %cd ~"
      ],
      "metadata": {
        "id": "yoXMSml0CLZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/Transliteration Dictionary/Roman_Devanagari_Translit_Dict.json' /content/"
      ],
      "metadata": {
        "id": "fblh_fOkslmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translitr = RomanToDevaTransliterator(translit_dict='/content/Roman_Devanagari_Translit_Dict.json')"
      ],
      "metadata": {
        "id": "kTOsBFmHy8BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/data_out"
      ],
      "metadata": {
        "id": "T-3hIjUoOerC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####AUGMENT AND TRANSLITERATE AND SAVE AUDIO"
      ],
      "metadata": {
        "id": "QBos7DX_UN7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", transliterator = translitr, augmentor = AudioAugmentor(), augment = True)\n",
        "preprocessor.preprocess(); #To include extensions in file ids in transcript file see method write_to_transcript(). Perhaps this feature should be included as an attribute in AudioPreprocessor class.\n"
      ],
      "metadata": {
        "id": "JonvutPqy5Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####WRITE TRANSCRIPTS IN PROPER FORMAT WITHOUT TRANSLITERATION (AUDIO_ID TRANSCRIPT). NO AUDIO SAVING"
      ],
      "metadata": {
        "id": "Y0Z1k6hbUWlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", augmentor = AudioAugmentor(), save_aud=False)\n",
        "preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "Sq4B48JbUZJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####TRANSLITERATE AND AUGMENT BUT DON'T SAVE AUDIO\n",
        "This will only create transcript file. Will not actually augment the audio but the augmented audio's transcript (same as the original) are duplicated in the transcript file with proper labels (i.e. augmented audio ids)"
      ],
      "metadata": {
        "id": "NCIOQqFbUm9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", transliterator = translitr, augmentor = AudioAugmentor(), augment = True,  save_aud=False)\n",
        "preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "WOqmQvdzUrqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####AUGMENT BUT DON'T SAVE AUDIO NO TRANSLITERATION"
      ],
      "metadata": {
        "id": "ODUhUf2Mij5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", transliterator = None, augmentor = AudioAugmentor(), augment = True,  save_aud=False)\n",
        "preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "Ah4q3Pqoiov4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/data_out/transcript.txt | wc -l\n"
      ],
      "metadata": {
        "id": "cuKGiNTKjTiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data_out/transcript.txt /content/drive/MyDrive/MSICE/native_augmented_transcript.txt"
      ],
      "metadata": {
        "id": "FW1c21zyjiSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####SAVE TO DRIVE"
      ],
      "metadata": {
        "id": "MMD5haK3U-Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/data_out.zip /content/data_out\n",
        "!cp /content/data_out.zip /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual_Augmented.zip"
      ],
      "metadata": {
        "id": "e04EBIGuhA4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BHATTA DATASET RESAMPLING, CONVERSION TO MONO"
      ],
      "metadata": {
        "id": "OmGuJ8ZU6KQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/Bhatta_Normalized_DataSet/\n",
        "!mkdir --parents /content/Bhatta_Normalized_DataSet/bharat1/ /content/Bhatta_Normalized_DataSet/ganNeshsir3/"
      ],
      "metadata": {
        "id": "5sa96wFrxZJs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/MSICE/Pure_Nepali_Labelled_Speech_Data/Dataset/Train/SECTEC /content/"
      ],
      "metadata": {
        "id": "Ftxs1uhRdfNs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/SECTEC"
      ],
      "metadata": {
        "id": "RSBXfUwDdonB",
        "outputId": "e5749226-5d06-4113-8c30-baa9d71f4b18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "dr-x------ 2 root root 4096 Dec 11 17:27 bharat1\n",
            "dr-x------ 2 root root 4096 Dec 11 17:28 ganNeshsir3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -hl /content/SECTEC/bharat1/ | head -n 10"
      ],
      "metadata": {
        "id": "oL8KYeKJdPzk",
        "outputId": "d93213e7-8184-47a6-fa4f-c4d54afcb422",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 52M\n",
            "-r-------- 1 root root  525K Dec 11 17:27 bharat10.wav\n",
            "-r-------- 1 root root  763K Dec 11 17:27 bharat110.wav\n",
            "-r-------- 1 root root  665K Dec 11 17:27 bharat111.wav\n",
            "-r-------- 1 root root  686K Dec 11 17:27 bharat112.wav\n",
            "-r-------- 1 root root  609K Dec 11 17:27 bharat113.wav\n",
            "-r-------- 1 root root  574K Dec 11 17:27 bharat114.wav\n",
            "-r-------- 1 root root  427K Dec 11 17:27 bharat115.wav\n",
            "-r-------- 1 root root  679K Dec 11 17:27 bharat116.wav\n",
            "-r-------- 1 root root  749K Dec 11 17:27 bharat117.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def normalize_bhatta_dataset(data_fol:str, out_fol:str, mono: bool, new_sample_rate: int) -> None:\n",
        "    data_fol = Path(data_fol)\n",
        "    out_fol = Path(out_fol)\n",
        "\n",
        "    #AUDIO\n",
        "    audio_ext_pattern = re.compile(r\"\\.wav$\")\n",
        "    aug = AudioAugmentor()\n",
        "    for path in data_fol.iterdir():\n",
        "        if not path.is_file() or not audio_ext_pattern.search(path.name):\n",
        "            continue\n",
        "        audio, sample_rate = torchaudio.load(path)\n",
        "        if mono:\n",
        "            audio = aug.convert_to_mono(audio_tensor = audio)\n",
        "        if new_sample_rate and sample_rate != new_sample_rate:\n",
        "            audio = aug.resample(audio, orig_sample_rate=sample_rate, new_sample_rate=new_sample_rate)\n",
        "        torchaudio.save(uri = f\"{out_fol}/{path.name}\", src = audio, sample_rate=new_sample_rate)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ba1DR7a7yD5r"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize_bhatta_dataset(data_fol = \"/content/SECTEC/bharat1\", out_fol = \"/content/Bhatta_Normalized_DataSet/bharat1/\", mono = True, new_sample_rate = 16000)\n",
        "!cp /content/SECTEC/bharat1/SECTEC_bharat1.trans.txt /content/Bhatta_Normalized_DataSet/bharat1/"
      ],
      "metadata": {
        "id": "A9m7RqjI28dN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/Bhatta_Normalized_DataSet/bharat1/SECTEC_bharat1.trans.txt | wc -l\n",
        "!ls /content/Bhatta_Normalized_DataSet/bharat1/ | grep 'wav' | wc -l"
      ],
      "metadata": {
        "id": "F84yjvRY3r5L",
        "outputId": "010ef56f-d4c9-4e12-c7e8-132aead7b00d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87\n",
            "87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -hl /content/Bhatta_Normalized_DataSet/bharat1/ | head -n 10"
      ],
      "metadata": {
        "id": "ats2WJW6d2OO",
        "outputId": "2e14a18a-e8cc-4bad-855f-d1b173b4b6ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 52M\n",
            "-rw-r--r-- 1 root root  526K Dec 11 17:30 bharat10.wav\n",
            "-rw-r--r-- 1 root root  764K Dec 11 17:30 bharat110.wav\n",
            "-rw-r--r-- 1 root root  666K Dec 11 17:30 bharat111.wav\n",
            "-rw-r--r-- 1 root root  687K Dec 11 17:30 bharat112.wav\n",
            "-rw-r--r-- 1 root root  610K Dec 11 17:30 bharat113.wav\n",
            "-rw-r--r-- 1 root root  575K Dec 11 17:30 bharat114.wav\n",
            "-rw-r--r-- 1 root root  428K Dec 11 17:30 bharat115.wav\n",
            "-rw-r--r-- 1 root root  680K Dec 11 17:30 bharat116.wav\n",
            "-rw-r--r-- 1 root root  750K Dec 11 17:30 bharat117.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalize_bhatta_dataset(data_fol = \"/content/SECTEC/ganNeshsir3\", out_fol = \"/content/Bhatta_Normalized_DataSet/ganNeshsir3\", mono = True, new_sample_rate = 16000)\n",
        "!cp /content/SECTEC/ganNeshsir3/SECTEC_ganNeshsir3.trans.txt /content/Bhatta_Normalized_DataSet/ganNeshsir3/"
      ],
      "metadata": {
        "id": "zNqui4cw4XUK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/Bhatta_Normalized_DataSet/ganNeshsir3/SECTEC_ganNeshsir3.trans.txt | wc -l\n",
        "!ls /content/Bhatta_Normalized_DataSet/ganNeshsir3/ | grep 'wav' | wc -l"
      ],
      "metadata": {
        "id": "2Z4HlWdy6Ni0",
        "outputId": "86c53d7a-5dbc-4686-9c07-73291bfeb9ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/Bhatta_Normalized_DataSet/"
      ],
      "metadata": {
        "id": "TQy3H3Cyf5NH",
        "outputId": "7698845f-9a88-4d38-c0b0-de1ad3161b34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "drwxr-xr-x 2 root root 4096 Dec 11 17:38 bharat1\n",
            "drwxr-xr-x 2 root root 4096 Dec 11 17:39 ganNeshsir3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Bhatta_Normalized_DataSet/\n",
        "!zip -r Bhatta_Normalized_DataSet.zip *\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "k9NV3fehf-Jc",
        "outputId": "29fa4e6f-4901-457c-c2b9-de63951c0271",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Bhatta_Normalized_DataSet\n",
            "  adding: bharat1/ (stored 0%)\n",
            "  adding: bharat1/bharat164.wav (deflated 15%)\n",
            "  adding: bharat1/bharat18.wav (deflated 16%)\n",
            "  adding: bharat1/bharat150.wav (deflated 17%)\n",
            "  adding: bharat1/bharat176.wav (deflated 16%)\n",
            "  adding: bharat1/bharat185.wav (deflated 17%)\n",
            "  adding: bharat1/bharat166.wav (deflated 18%)\n",
            "  adding: bharat1/bharat168.wav (deflated 15%)\n",
            "  adding: bharat1/bharat133.wav (deflated 16%)\n",
            "  adding: bharat1/bharat154.wav (deflated 16%)\n",
            "  adding: bharat1/bharat146.wav (deflated 16%)\n",
            "  adding: bharat1/bharat160.wav (deflated 18%)\n",
            "  adding: bharat1/bharat138.wav (deflated 15%)\n",
            "  adding: bharat1/bharat12.wav (deflated 18%)\n",
            "  adding: bharat1/bharat110.wav (deflated 14%)\n",
            "  adding: bharat1/bharat114.wav (deflated 15%)\n",
            "  adding: bharat1/bharat161.wav (deflated 17%)\n",
            "  adding: bharat1/bharat167.wav (deflated 20%)\n",
            "  adding: bharat1/bharat178.wav (deflated 15%)\n",
            "  adding: bharat1/bharat19.wav (deflated 15%)\n",
            "  adding: bharat1/bharat121.wav (deflated 18%)\n",
            "  adding: bharat1/bharat145.wav (deflated 14%)\n",
            "  adding: bharat1/bharat156.wav (deflated 19%)\n",
            "  adding: bharat1/bharat126.wav (deflated 15%)\n",
            "  adding: bharat1/bharat135.wav (deflated 16%)\n",
            "  adding: bharat1/bharat143.wav (deflated 14%)\n",
            "  adding: bharat1/bharat10.wav (deflated 14%)\n",
            "  adding: bharat1/bharat184.wav (deflated 15%)\n",
            "  adding: bharat1/bharat122.wav (deflated 14%)\n",
            "  adding: bharat1/bharat117.wav (deflated 17%)\n",
            "  adding: bharat1/bharat129.wav (deflated 17%)\n",
            "  adding: bharat1/bharat127.wav (deflated 15%)\n",
            "  adding: bharat1/SECTEC_bharat1.trans.txt (deflated 78%)\n",
            "  adding: bharat1/bharat115.wav (deflated 18%)\n",
            "  adding: bharat1/bharat186.wav (deflated 18%)\n",
            "  adding: bharat1/bharat124.wav (deflated 16%)\n",
            "  adding: bharat1/bharat113.wav (deflated 16%)\n",
            "  adding: bharat1/bharat17.wav (deflated 15%)\n",
            "  adding: bharat1/bharat153.wav (deflated 14%)\n",
            "  adding: bharat1/bharat165.wav (deflated 19%)\n",
            "  adding: bharat1/bharat130.wav (deflated 16%)\n",
            "  adding: bharat1/bharat120.wav (deflated 16%)\n",
            "  adding: bharat1/bharat170.wav (deflated 18%)\n",
            "  adding: bharat1/bharat112.wav (deflated 16%)\n",
            "  adding: bharat1/bharat152.wav (deflated 17%)\n",
            "  adding: bharat1/bharat159.wav (deflated 13%)\n",
            "  adding: bharat1/bharat119.wav (deflated 14%)\n",
            "  adding: bharat1/bharat148.wav (deflated 13%)\n",
            "  adding: bharat1/bharat173.wav (deflated 14%)\n",
            "  adding: bharat1/bharat182.wav (deflated 15%)\n",
            "  adding: bharat1/bharat16.wav (deflated 15%)\n",
            "  adding: bharat1/bharat177.wav (deflated 15%)\n",
            "  adding: bharat1/bharat162.wav (deflated 16%)\n",
            "  adding: bharat1/bharat123.wav (deflated 21%)\n",
            "  adding: bharat1/bharat134.wav (deflated 22%)\n",
            "  adding: bharat1/bharat137.wav (deflated 16%)\n",
            "  adding: bharat1/bharat128.wav (deflated 13%)\n",
            "  adding: bharat1/bharat181.wav (deflated 18%)\n",
            "  adding: bharat1/bharat111.wav (deflated 16%)\n",
            "  adding: bharat1/bharat169.wav (deflated 17%)\n",
            "  adding: bharat1/bharat118.wav (deflated 14%)\n",
            "  adding: bharat1/bharat147.wav (deflated 15%)\n",
            "  adding: bharat1/bharat171.wav (deflated 16%)\n",
            "  adding: bharat1/bharat131.wav (deflated 15%)\n",
            "  adding: bharat1/bharat14.wav (deflated 14%)\n",
            "  adding: bharat1/bharat180.wav (deflated 20%)\n",
            "  adding: bharat1/bharat136.wav (deflated 17%)\n",
            "  adding: bharat1/bharat157.wav (deflated 19%)\n",
            "  adding: bharat1/bharat158.wav (deflated 18%)\n",
            "  adding: bharat1/bharat175.wav (deflated 16%)\n",
            "  adding: bharat1/bharat172.wav (deflated 15%)\n",
            "  adding: bharat1/bharat140.wav (deflated 14%)\n",
            "  adding: bharat1/bharat13.wav (deflated 17%)\n",
            "  adding: bharat1/bharat125.wav (deflated 15%)\n",
            "  adding: bharat1/bharat163.wav (deflated 18%)\n",
            "  adding: bharat1/bharat139.wav (deflated 16%)\n",
            "  adding: bharat1/bharat142.wav (deflated 19%)\n",
            "  adding: bharat1/bharat11.wav (deflated 15%)\n",
            "  adding: bharat1/bharat15.wav (deflated 18%)\n",
            "  adding: bharat1/bharat149.wav (deflated 16%)\n",
            "  adding: bharat1/bharat183.wav (deflated 14%)\n",
            "  adding: bharat1/bharat155.wav (deflated 17%)\n",
            "  adding: bharat1/bharat116.wav (deflated 15%)\n",
            "  adding: bharat1/bharat151.wav (deflated 17%)\n",
            "  adding: bharat1/bharat141.wav (deflated 14%)\n",
            "  adding: bharat1/bharat174.wav (deflated 16%)\n",
            "  adding: bharat1/bharat179.wav (deflated 15%)\n",
            "  adding: bharat1/bharat132.wav (deflated 14%)\n",
            "  adding: bharat1/bharat144.wav (deflated 14%)\n",
            "  adding: ganNeshsir3/ (stored 0%)\n",
            "  adding: ganNeshsir3/ganNeshsir390.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir351.wav (deflated 7%)\n",
            "  adding: ganNeshsir3/ganNeshsir337.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir398.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/SECTEC_ganNeshsir3.trans.txt (deflated 79%)\n",
            "  adding: ganNeshsir3/ganNeshsir387.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir339.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir332.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir327.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir354.wav (deflated 12%)\n",
            "  adding: ganNeshsir3/ganNeshsir33.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir311.wav (deflated 8%)\n",
            "  adding: ganNeshsir3/ganNeshsir349.wav (deflated 7%)\n",
            "  adding: ganNeshsir3/ganNeshsir313.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir369.wav (deflated 8%)\n",
            "  adding: ganNeshsir3/ganNeshsir32.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir363.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir377.wav (deflated 14%)\n",
            "  adding: ganNeshsir3/ganNeshsir34.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir328.wav (deflated 8%)\n",
            "  adding: ganNeshsir3/ganNeshsir36.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir312.wav (deflated 7%)\n",
            "  adding: ganNeshsir3/ganNeshsir389.wav (deflated 12%)\n",
            "  adding: ganNeshsir3/ganNeshsir323.wav (deflated 8%)\n",
            "  adding: ganNeshsir3/ganNeshsir399.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir35.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir347.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir384.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir340.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir379.wav (deflated 8%)\n",
            "  adding: ganNeshsir3/ganNeshsir31.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir364.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir361.wav (deflated 12%)\n",
            "  adding: ganNeshsir3/ganNeshsir322.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir386.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir365.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir333.wav (deflated 8%)\n",
            "  adding: ganNeshsir3/ganNeshsir344.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir318.wav (deflated 8%)\n",
            "  adding: ganNeshsir3/ganNeshsir388.wav (deflated 7%)\n",
            "  adding: ganNeshsir3/ganNeshsir373.wav (deflated 8%)\n",
            "  adding: ganNeshsir3/ganNeshsir316.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir317.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir382.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir355.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir330.wav (deflated 12%)\n",
            "  adding: ganNeshsir3/ganNeshsir380.wav (deflated 12%)\n",
            "  adding: ganNeshsir3/ganNeshsir370.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir326.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir320.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir342.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir343.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir396.wav (deflated 8%)\n",
            "  adding: ganNeshsir3/ganNeshsir325.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir336.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir372.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir310.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir319.wav (deflated 8%)\n",
            "  adding: ganNeshsir3/ganNeshsir360.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir395.wav (deflated 12%)\n",
            "  adding: ganNeshsir3/ganNeshsir314.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir357.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir394.wav (deflated 7%)\n",
            "  adding: ganNeshsir3/ganNeshsir321.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir397.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir335.wav (deflated 7%)\n",
            "  adding: ganNeshsir3/ganNeshsir315.wav (deflated 8%)\n",
            "  adding: ganNeshsir3/ganNeshsir324.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir367.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir348.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir392.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir375.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir37.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir338.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir358.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir356.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir371.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir368.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir374.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir385.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir391.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir353.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir331.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir352.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir334.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir359.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir341.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir30.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir366.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir376.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir393.wav (deflated 8%)\n",
            "  adding: ganNeshsir3/ganNeshsir381.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir345.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir329.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir346.wav (deflated 10%)\n",
            "  adding: ganNeshsir3/ganNeshsir362.wav (deflated 8%)\n",
            "  adding: ganNeshsir3/ganNeshsir383.wav (deflated 9%)\n",
            "  adding: ganNeshsir3/ganNeshsir38.wav (deflated 11%)\n",
            "  adding: ganNeshsir3/ganNeshsir378.wav (deflated 14%)\n",
            "  adding: ganNeshsir3/ganNeshsir39.wav (deflated 8%)\n",
            "  adding: ganNeshsir3/ganNeshsir350.wav (deflated 8%)\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/Bhatta_Normalized_DataSet/Bhatta_Normalized_DataSet.zip /content/drive/MyDrive/MSICE/"
      ],
      "metadata": {
        "id": "ZZMB-S6M6933"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/drive/MyDrive/MSICE"
      ],
      "metadata": {
        "id": "CRg6-hiE7L1-",
        "outputId": "070c02c0-6822-436c-c8b9-a95e678c620d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2479770\n",
            "-rw------- 1 root root  155996529 Sep 23  2024 '074BCT audio dataset-20240923T044153Z-001.zip'\n",
            "drwx------ 2 root root       4096 Dec  7  2024  Articles\n",
            "-rw------- 1 root root    4321720 Dec  9 19:51  automated_cs_asr_native_numless_punctless_transcript.txt\n",
            "-rw------- 1 root root   35550936 Dec 11 17:41  Bhatta_Normalized_DataSet.zip\n",
            "-rw------- 1 root root  371563209 Dec  8 18:33  Bijaya_Khanal_Automated_CS_ASR_Dataset.zip\n",
            "-rw------- 1 root root     129462 Sep 19 09:47 'Changes transcript.txt'\n",
            "drwx------ 2 root root       4096 Oct 30 08:40  CM_Nep_Eng_Fine-tuned_Results\n",
            "drwx------ 2 root root       4096 Nov 17 12:44  CM_Text_Corpus\n",
            "drwx------ 2 root root       4096 Aug 11 09:23 'Dependency Corrections'\n",
            "drwx------ 2 root root       4096 Nov  4 06:40  English_Nepali_CS_Audio_PT\n",
            "drwx------ 2 root root       4096 Dec  1 19:18  English_Nepali_CS_Data_Manual\n",
            "-rw------- 1 root root   81637102 Dec 10 08:10  English_Nepali_CS_Data_Manual_Augmented_WO_ext.zip\n",
            "-rw------- 1 root root   81637876 Sep  6 08:19  English_Nepali_CS_Data_Manual_Augmented.zip\n",
            "drwx------ 2 root root       4096 Dec  1 19:18  English_Nepali_CS_Data_Predetermined\n",
            "drwx------ 2 root root       4096 Dec  1 19:20  English_Nepali_CS_Data_Predetermined_2\n",
            "-rw------- 1 root root   17434011 Dec  8 17:45  English_Nepali_CS_Data_Predetermined_2.zip\n",
            "-rw------- 1 root root    5077070 Dec 10 08:14  English_Nepali_CS_Data_Predetermined.zip\n",
            "drwx------ 2 root root       4096 Dec  4  2024 'English To Nepali Transliteration Dictionary'\n",
            "drwx------ 2 root root       4096 Nov  7 04:08 'Jiri Community Library Transcripts'\n",
            "-rw------- 1 root root    1462580 Dec 10 08:10  LK_About_Love_Chekhov.zip\n",
            "-rw------- 1 root root       8731 Dec  9 18:32  Loknath_Koirala_About_Love_Chekhov_native_numless_punctless_transcript.txt\n",
            "-rw------- 1 root root       8700 Dec  8 17:22  Loknath_Koirala_About_Love_Chekhov_transcript.txt\n",
            "-rw------- 1 root root     916460 Dec  9 16:30  native_augmented_numless_punctless_transcript.txt\n",
            "-rw------- 1 root root     916908 Oct 21 16:17  native_augmented_transcript.txt\n",
            "-rw------- 1 root root     129398 Dec  9 16:29  native_numless_punctless_transcript.txt\n",
            "drwx------ 2 root root       4096 Oct 14  2024 'Óbuda University '\n",
            "drwx------ 2 root root       4096 Jan 30  2025  Predetermined_CS_Texts\n",
            "-rw------- 1 root root      19840 Dec  9 16:32  pt_2_native_numless_punctless_transcript.txt\n",
            "-rw------- 1 root root      19903 Dec  8 17:16  pt_2_native_transcript.txt\n",
            "-rw------- 1 root root      41914 Dec  9 16:31  pt_native_numless_punctless_transcript.txt\n",
            "-rw------- 1 root root      42030 Nov  4 16:08  pt_native_transcript.txt\n",
            "drwx------ 2 root root       4096 Jun 23 05:59  Pure_Nepali_Labelled_Speech_Data\n",
            "-rw------- 1 root root  128120317 Jun 23 14:49  real_time_test-20240823T071018Z-001.zip\n",
            "drwx------ 2 root root       4096 Oct 31 16:15  Romanized_Nepali_Transliteration\n",
            "-rw------- 1 root root        121 Dec  9 16:36  Satbeej_numless_punctless.txt\n",
            "-rw------- 1 root root        121 Dec  8 18:51  Satbeej.txt\n",
            "-rw------- 1 root root      23922 Dec  8 18:51  Satbeej.zip\n",
            "-rw------- 1 root root      17047 Dec  9 16:36  SECTEC_bharat1.trans_numless_punctless.txt\n",
            "-rw------- 1 root root      18702 Dec  9 16:36  SECTEC_ganNeshsir3.trans_numless_punctless.txt\n",
            "drwx------ 2 root root       4096 Feb  7  2024 'SEM II'\n",
            "drwx------ 2 root root       4096 Mar 27  2024 'SEM III'\n",
            "drwx------ 2 root root       4096 Dec  7  2024 'SEMS III & IV'\n",
            "-rw------- 1 root root     962802 Dec  9 16:34  slr54_numless_punctless_transcript.txt\n",
            "-rw------- 1 root root 1488544602 Dec 11 14:22  SLR54_Subset_30K.zip\n",
            "-rw------- 1 root root  162589600 Dec  7 18:01  SLR54_Subset_Normalized.zip\n",
            "-rw------- 1 root root     943870 Dec  7 18:02  slr54_transcript.txt\n",
            "-rw------- 1 root root     943870 Dec  7 17:44  transcription.txt\n",
            "-rw------- 1 root root     129462 Sep 17 16:57  transcript.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CS PREDETERMINED"
      ],
      "metadata": {
        "id": "m1mYGpfFQADv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r data/\n",
        "!rm -r data_out/"
      ],
      "metadata": {
        "id": "4LyQsHELQ8Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Predetermined/ /content/data/"
      ],
      "metadata": {
        "id": "CCgo5eFxQDNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####AUGMENT DON'T SAVE AUDIO NO TRANSLITERATION"
      ],
      "metadata": {
        "id": "ws9gg8TOQn32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", transliterator = None, augmentor = AudioAugmentor(), augment = False,  save_aud=False)\n",
        "preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "nSdkPyxtQJRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -20 /content/data_out/transcript.txt"
      ],
      "metadata": {
        "id": "1krBiavKQ1qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CS PREDETERMINED 2"
      ],
      "metadata": {
        "id": "Y4gKwrUYtd7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/data_out/\n",
        "# !rm -r /content/data/"
      ],
      "metadata": {
        "id": "VuwKr15ethod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/drive/MyDrive/MSICE/"
      ],
      "metadata": {
        "id": "kY5_Rot72DWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Predetermined_2/ /content/data/"
      ],
      "metadata": {
        "id": "B3gWxU_mtlli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####NO TRANSLITERATION, NO AUGMENTATION, SAVE AUDIO"
      ],
      "metadata": {
        "id": "nLeGzC9KuBzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", transcr_name = ('transcription.txt',), transliterator = None, augmentor = AudioAugmentor(), augment = False,  save_aud=True)\n",
        "preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "V5LQFdMzuA9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -40 /content/data_out/transcript.txt"
      ],
      "metadata": {
        "id": "T2CYgRVTuoLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/data_out/\n",
        "# !zip English_Nepali_CS_Data_Predetermined_2.zip *\n",
        "# %cd /content"
      ],
      "metadata": {
        "id": "lHdt2Vdw0dbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data_out/transcript.txt /content/drive/MyDrive/MSICE/pt_2_native_transcript.txt"
      ],
      "metadata": {
        "id": "gxK1nYL43uAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SLR54 SUBSET"
      ],
      "metadata": {
        "id": "jtoF3PX-KymS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/data_out/\n",
        "!rm -r /content/data/"
      ],
      "metadata": {
        "id": "QVQZyGy5UEq3",
        "outputId": "7b095825-f584-412b-d18c-6de5d9161229",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/data_out/': No such file or directory\n",
            "rm: cannot remove '/content/data/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/MSICE/SLR54_Subset.zip /content/"
      ],
      "metadata": {
        "id": "l7ptebDkQPV7",
        "outputId": "831a7e4e-0f7e-4dd0-c2c3-6ab492b32001",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/MSICE/SLR54_Subset.zip': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir --parents /content/data/SLR54_Subset/"
      ],
      "metadata": {
        "id": "ESKAC1wJRhL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/SLR54_Subset.zip -d /content/data/SLR54_Subset/"
      ],
      "metadata": {
        "id": "DiZsBenOQUc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 /content/data/SLR54_Subset/transcription.txt"
      ],
      "metadata": {
        "id": "dnHvth4OUJZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/data_out/"
      ],
      "metadata": {
        "id": "V6YMtj-IX9oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def normalize_dataset(data_fol:str, out_fol:str, mono: bool, new_sample_rate: int) -> None:\n",
        "    data_fol = Path(data_fol)\n",
        "    out_fol = Path(out_fol)\n",
        "\n",
        "    #AUDIO\n",
        "    audio_ext_pattern = re.compile(r\"\\.flac$\")\n",
        "    aug = AudioAugmentor()\n",
        "    for path in data_fol.iterdir():\n",
        "        if not path.is_file() or not audio_ext_pattern.search(path.name):\n",
        "            continue\n",
        "        audio, sample_rate = torchaudio.load(path)\n",
        "        if mono:\n",
        "            audio = aug.convert_to_mono(audio_tensor = audio)\n",
        "        if new_sample_rate and sample_rate != new_sample_rate:\n",
        "            audio = aug.resample(audio, orig_sample_rate=sample_rate, new_sample_rate=new_sample_rate)\n",
        "        torchaudio.save(uri = f\"{out_fol}/{path.name}\", src = audio, sample_rate=new_sample_rate)\n"
      ],
      "metadata": {
        "id": "AuILOUh0XDIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize_dataset(data_fol = '/content/data/SLR54_Subset/',out_fol = '/content/data_out/', mono = True, new_sample_rate = 16000)"
      ],
      "metadata": {
        "id": "i1VSb-8sXps0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/data_out/*|  wc -l"
      ],
      "metadata": {
        "id": "8o2NKSPhcSXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l /content/data/SLR54_Subset/transcription.txt"
      ],
      "metadata": {
        "id": "__uLZIkMcbkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/data_out/"
      ],
      "metadata": {
        "id": "Cf8_xaqhdqdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip SLR54_Subset_Normalized.zip *mp3"
      ],
      "metadata": {
        "id": "7WRyhd72dsEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "xDxkhthod2kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data_out/SLR54_Subset_Normalized.zip /content/drive/MyDrive/MSICE/"
      ],
      "metadata": {
        "id": "YsgBrwN2eBCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data/SLR54_Subset/transcription.txt /content/drive/MyDrive/MSICE/slr54_transcript.txt"
      ],
      "metadata": {
        "id": "ACgEku8LeHEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/drive/MyDrive/MSICE/SLR54_Subset.zip"
      ],
      "metadata": {
        "id": "fvMhllvzeQFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/drive/MyDrive/MSICE/"
      ],
      "metadata": {
        "id": "kke82aEceVSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LOKNATH KOIRALA CHEKHOV DATASET"
      ],
      "metadata": {
        "id": "4s7Gmttgkq2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r data_out/\n",
        "!rm -r data/"
      ],
      "metadata": {
        "id": "rok2_0j7le7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/data/"
      ],
      "metadata": {
        "id": "hYsk3hRupW6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -hl /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/Loknath_Koirala_About_Love_Chekhov/"
      ],
      "metadata": {
        "id": "5poq6jgnkxZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/Loknath_Koirala_About_Love_Chekhov /content/data/Loknath_Koirala_About_Love_Chekhov"
      ],
      "metadata": {
        "id": "GuChyVSHlSn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -hl /content/data/Loknath_Koirala_About_Love_Chekhov/"
      ],
      "metadata": {
        "id": "GJpYFqj9oy1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", transliterator = None, augmentor = AudioAugmentor(), augment = False,  save_aud=True)\n",
        "preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "LgTwpm6qlg9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -hl /content/data_out/"
      ],
      "metadata": {
        "id": "yNaE3vXdplMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -10 /content/data_out/transcript.txt"
      ],
      "metadata": {
        "id": "pPh7s1IypqKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/data_out/"
      ],
      "metadata": {
        "id": "1__ghzIqp4rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip LK_About_Love_Chekhov.zip *"
      ],
      "metadata": {
        "id": "3I856t37p8NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "yvMkEckSqGuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data_out/LK_About_Love_Chekhov.zip /content/drive/MyDrive/MSICE/"
      ],
      "metadata": {
        "id": "OKeR4WnkqYDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data_out/transcript.txt /content/"
      ],
      "metadata": {
        "id": "NzZmrut6qcsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/transcript.txt '/content/drive/My Drive/MSICE/Loknath_Koirala_About_Love_Chekhov_transcript.txt'"
      ],
      "metadata": {
        "id": "gVTHGW2gqge1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}