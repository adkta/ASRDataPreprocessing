{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzvkLFEwM0RMKzuorliD5h"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##DESIGN\n",
        "\"\"\"\n",
        "Preprocessing\n",
        "\n",
        "  Convert To Mono\n",
        "  Audio Enhancement (optional)\n",
        "  Label transliteration\n",
        "  Remove punctuation\n",
        "  Augmentation\n",
        "  Label copying\n",
        "  Necessary folder arrangement to load data and feed into wav2vec2\n",
        "\n",
        "\n",
        "Data\n",
        "  Folder1\n",
        "    audio_1\n",
        "    audio_2\n",
        "    ...\n",
        "    transcript    \n",
        "  Folder2\n",
        "    audio_1\n",
        "    audio_2\n",
        "    ...\n",
        "    transcript\n",
        "  ...\n",
        "\n",
        "DataFolderPath\n",
        "->\n",
        "Preprocessor\n",
        "(walks data folder)\n",
        "searches for transcript file, finds file and creates transliterated transcript file/ generates a pandas transliterated row for the file.\n",
        "Each audio is augmented (list of augmentation is provided) corresponding label\n",
        "->\n",
        "Transliteration using dictionary\n",
        "->\n",
        "Augmentation\n",
        "->\n",
        "Label Copy\n",
        "->\n",
        "Folder format\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "D8gy1vonp0l0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SETUP"
      ],
      "metadata": {
        "id": "FX0PnyeYNp8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchcodec"
      ],
      "metadata": {
        "id": "hbpXmZwGn8aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install g2p_en"
      ],
      "metadata": {
        "id": "h-CF91aBswAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dXhHz3vIi_CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nepali-num2word"
      ],
      "metadata": {
        "id": "9Z2VtVzukhG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/adkta/nepali_arabic_num_to_word.git"
      ],
      "metadata": {
        "id": "9ny6pYyZkh5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/transliteration"
      ],
      "metadata": {
        "id": "phuzjpfuM1WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/adkta/transliteration.git"
      ],
      "metadata": {
        "id": "W3H9FIY5pBet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.path)"
      ],
      "metadata": {
        "id": "jBWr2FVIullx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from typing import Union, Optional\n",
        "from pathlib import Path\n",
        "from transliteration.transliterator import Transliterator\n",
        "from transliteration.transliterators import RomanToDevaTransliterator\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections.abc import Generator"
      ],
      "metadata": {
        "id": "yegl7DcSVXKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transliteration.transliterator import TranslitDict"
      ],
      "metadata": {
        "id": "ONGdQx675b2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LOGGING CONFIGURATION"
      ],
      "metadata": {
        "id": "WzAjhysBdPt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "LOG_LEVEL = logging.INFO\n",
        "_log_path = '/content/preprocessing.log'\n",
        "logger = logging.getLogger(\"preprocessing\")\n",
        "logger.setLevel(LOG_LEVEL)\n",
        "_handler = logging.FileHandler(_log_path)\n",
        "_handler.setLevel(LOG_LEVEL)\n",
        "_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
        "logger.addHandler(_handler)"
      ],
      "metadata": {
        "id": "YIiuVD4X6FMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PREPROCESSING CLASSES"
      ],
      "metadata": {
        "id": "Kyk5CNuBQ_WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Utils:\n",
        "    @staticmethod\n",
        "    def get_matching_files(data_fol: Path, file_pattern: str) -> Generator[Path, None, None]:\n",
        "        file_pattern = re.compile(file_pattern)\n",
        "        for f in data_fol.iterdir():\n",
        "            if file_pattern.search(f.as_posix()):\n",
        "                yield f"
      ],
      "metadata": {
        "id": "mcA-IIERLZy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onbtow9TtXMo"
      },
      "outputs": [],
      "source": [
        "import torchaudio\n",
        "import torch\n",
        "\n",
        "class AudioAugmentor:\n",
        "    def __init__(self) -> None:\n",
        "        self.download_assets()\n",
        "\n",
        "    def download_assets(self) -> None:\n",
        "        rir_loc = torchaudio.utils._download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo-8000hz.wav\")\n",
        "        noise_loc = torchaudio.utils._download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo-8000hz.wav\")\n",
        "        self.rir, self.rir_sample_rate = torchaudio.load(rir_loc)\n",
        "        self.noise, self.noise_sample_rate = torchaudio.load(noise_loc)\n",
        "        self.noise = self.noise/torch.linalg.vector_norm(self.noise)\n",
        "\n",
        "    def resample_assets(self, new_sample_rate: int) -> None:\n",
        "        self.rir = torchaudio.transforms.Resample(orig_freq=self.rir_sample_rate, new_freq=new_sample_rate)(self.rir)\n",
        "        self.noise = torchaudio.transforms.Resample(orig_freq=self.noise_sample_rate, new_freq=new_sample_rate)(self.noise)\n",
        "\n",
        "    def frame_count(self, waveform: torch.Tensor) -> int:\n",
        "        return waveform.shape[1]\n",
        "\n",
        "    def adjust_noise_frame_count_for_add(self, waveform: torch.Tensor, noise: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Noise adjustment for addition to signal\n",
        "        \"\"\"\n",
        "        noise_frame_count = self.frame_count(noise)\n",
        "        signal_frame_count = self.frame_count(waveform)\n",
        "        if noise_frame_count == signal_frame_count:\n",
        "            pass\n",
        "        elif noise_frame_count > signal_frame_count:\n",
        "            noise = noise[:, :signal_frame_count]\n",
        "        else:\n",
        "            quo, rem= divmod(signal_frame_count, noise_frame_count)\n",
        "            repeated_noise_list=[]\n",
        "            for _ in range(quo):\n",
        "                repeated_noise_list.append(noise)\n",
        "            repeated_noise_list.append(noise[:, :rem])\n",
        "            noise = torch.cat(repeated_noise_list, dim = 1)\n",
        "        return noise\n",
        "\n",
        "    def validate_audio_data(self, audio_data: Union[str, Path, torch.Tensor]) -> torch.Tensor:\n",
        "        assert audio_data.is_file(), \"audio_data must be a torch.Tensor, str path to an audio file or Path object to an audio file\"\n",
        "\n",
        "    def convert_to_mono(self, audio_tensor: torch.Tensor) -> torch.Tensor:\n",
        "        if audio_tensor.shape[0] == 1:\n",
        "            return audio_tensor\n",
        "        return torch.mean(audio_tensor, dim=0, keepdim=True)\n",
        "\n",
        "    def resample(self, waveform: torch.Tensor, orig_sample_rate: int, new_sample_rate: int) -> torch.Tensor:\n",
        "        return torchaudio.transforms.Resample(orig_freq=orig_sample_rate, new_freq=new_sample_rate)(waveform)\n",
        "\n",
        "    def shift_pitch(self, audio_data: torch.Tensor, sample_rate: int) -> torch.Tensor:\n",
        "        return torchaudio.transforms.PitchShift(sample_rate = sample_rate, n_steps = 2)(audio_data)\n",
        "\n",
        "    def add_background_crowd(self, audio_data: torch.Tensor, snr: int) -> torch.Tensor:\n",
        "        adj_resampled_noise = self.adjust_noise_frame_count_for_add(waveform = audio_data, noise = self.noise)\n",
        "        add_noise = torchaudio.transforms.AddNoise()\n",
        "        noisy_audio = add_noise(waveform = audio_data, noise = adj_resampled_noise, snr = torch.tensor([snr]))\n",
        "        return noisy_audio\n",
        "\n",
        "    def add_white_noise(self, audio_data: torch.Tensor, snr: int, variance: int) -> torch.Tensor:\n",
        "        white_noise = torch.randn_like(audio_data) * variance\n",
        "        white_noisy_audio = torchaudio.functional.add_noise(audio_data, white_noise,snr=torch.tensor([snr]))\n",
        "        return white_noisy_audio\n",
        "\n",
        "    def add_room_reverb(self, audio_data: torch.Tensor) -> torch.Tensor:\n",
        "        return torchaudio.functional.fftconvolve(audio_data, self.rir)\n",
        "\n",
        "    def perturb_speed(self, audio_data: torch.Tensor, sample_rate: int, factors: list[float]) -> torch.Tensor:\n",
        "        speed_perturb = torchaudio.transforms.SpeedPerturbation(orig_freq= sample_rate, factors = factors)\n",
        "        perturbed_audio, _ = speed_perturb(waveform = audio_data)\n",
        "        return perturbed_audio\n",
        "\n",
        "    def apply_low_pass_filter(self, audio_data: torch.Tensor, sample_rate: int) -> torch.Tensor:\n",
        "        req_effect = \"lowpass=frequency=1000\"\n",
        "        effector = torchaudio.io.AudioEffector(effect=req_effect)\n",
        "        filtered_audio_list = []\n",
        "        for chunk in effector.stream(waveform=audio_data.T, sample_rate = sample_rate, frames_per_chunk = 48000):\n",
        "            filtered_audio_list.append(chunk)\n",
        "        filtered_audio = torch.cat(filtered_audio_list, dim=0).T\n",
        "        return filtered_audio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import IO\n",
        "from transliteration.transliterator import Transliterator\n",
        "\n",
        "\n",
        "class AudioPreprocessor:\n",
        "    \"\"\"\n",
        "    Audio identifiers in the transcript file will only be searched non-recursively in the folder housing the transcript file.\n",
        "    Currently the preprocessor expects the following format in the transcript file.\n",
        "    Each line corresponds to audio_<audio_number>.<audio_ext>. Eg. line 1 would be for audio_1.mp3, line 2 for audio_2.mp3 and so on.\n",
        "    A future to do may process the file in format: audio_id<delimiter>label (which is the output format)\n",
        "    \"\"\"\n",
        "\n",
        "    audio_ext_pattern = r\"\\.mp3$|\\.wav$|\\.opus$\"\n",
        "    DEFAULT_RESAMPLE_RATE = 16000\n",
        "    TKNZR_PATTERN = re.compile(TranslitDict.PUNCT_SPACE_REGEX)\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_folder: str,\n",
        "        out_folder: str,\n",
        "        skip: Union[tuple[str],None] = None,\n",
        "        transcr_name:tuple[str] = (\"transcript.txt\",),\n",
        "        out_transcr_name: str = \"transcript.txt\",\n",
        "        transliterator: Optional[Transliterator] = None,\n",
        "        save_aud: bool = True,\n",
        "        augmentor: Optional[AudioAugmentor] = None,\n",
        "        mono: bool = True,\n",
        "        resample_rate: Optional[int] = DEFAULT_RESAMPLE_RATE,\n",
        "        augment: bool = False\n",
        "        ) -> None:\n",
        "        \"\"\"\n",
        "        :param data_folder: str Input data folder\n",
        "        :param out_folder: str Output folder\n",
        "        :param skip: Union[tuple[str], None] List of files/folders to skip\n",
        "        :param transcr_name: str List of names that qualify as transcript files\n",
        "        :param transliterator: Optional[Transliterator] Transliterator to use. If not specified will not transliterate labels\n",
        "        :param augmentor: Augmentor Augmentor to use. If not specified, will not augment the audio\n",
        "        :param mono: bool Convert to mono channel\n",
        "        :param resample_rate: int Resample rate\n",
        "        \"\"\"\n",
        "        self.data_folder = Path(data_folder)\n",
        "        self.out_folder = Path(out_folder)\n",
        "        self.skip = skip\n",
        "        self.transcr_name = transcr_name\n",
        "        self.out_transcr_name = out_transcr_name\n",
        "        self.transliterator = transliterator\n",
        "        self.save_aud = save_aud\n",
        "        self.augmentor = augmentor\n",
        "        self.mono = mono\n",
        "        self.resample_rate = resample_rate\n",
        "        self.augment = augment\n",
        "\n",
        "    def is_audio(self, path: Path) -> bool:\n",
        "        return path.is_file() and path.name.endswith(AudioPreprocessor.audio_ext)\n",
        "\n",
        "    def get_transcr_file(self, folder: Path) -> Optional[Path]:\n",
        "        transcript_files = []\n",
        "        for fn in self.transcr_name:\n",
        "            logger.info(f\"Searching for {fn} in {folder}\")\n",
        "            if transcript_file := list(folder.glob(fn)):\n",
        "                transcript_files.extend(transcript_file)\n",
        "\n",
        "        assert len(transcript_files) < 2, \"More than one transcript file\"\n",
        "        return transcript_files[0] if transcript_files else None\n",
        "\n",
        "    def get_audio_files(self, folder: Path) -> Generator[Path, None, None]:\n",
        "        return Utils.get_matching_files(data_fol = folder, file_pattern = AudioPreprocessor.audio_ext_pattern)\n",
        "\n",
        "    def get_transcripts(self, transcript_file: Path) -> Generator[str, None, None]:\n",
        "        with open(transcript_file, 'r') as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                  continue\n",
        "                if self.transliterator:\n",
        "                  line = self.transliterate_line(line)\n",
        "                yield line\n",
        "\n",
        "    def transliterate_line(self, line: str) -> str:\n",
        "        words = AudioPreprocessor.TKNZR_PATTERN.split(line)\n",
        "        tl_words = []\n",
        "        for word in words:\n",
        "            if self.transliterator.for_transliteration(word):\n",
        "                word = self.transliterator.translit(word)\n",
        "            tl_words.append(word)\n",
        "        return \" \".join(tl_words)\n",
        "\n",
        "    def get_audio_label_dict(self, folder: Path) -> Optional[dict[Path, str]]:\n",
        "        transcript_file = self.get_transcr_file(folder)\n",
        "        if not transcript_file:\n",
        "            return None\n",
        "        numbered_audio_filter = lambda x: len(x.stem.split('_')) == 2\n",
        "        audio_num = lambda x: int(x.stem.split('_')[1])\n",
        "        sorted_audio_path: list[Path] = sorted(filter(numbered_audio_filter, self.get_audio_files(folder)), key = audio_num)\n",
        "        transcripts: Generator[str, None, None] = self.get_transcripts(transcript_file)\n",
        "        audio_label_dict:dict[Path, str] = dict(zip(sorted_audio_path, transcripts))\n",
        "        return audio_label_dict\n",
        "\n",
        "    def write_to_transcript(self, audio_path: Path, label: str, out_transcr_file: IO, ext: bool = False) -> None:\n",
        "        audio_id = audio_path.stem #additional assignment for code readability. Con: requires 2 assignment statements if ext = True.\n",
        "        if ext:\n",
        "            audio_id = audio_path.name\n",
        "        logger.debug(f\"Writing to {out_transcr_file}\")\n",
        "        out_transcr_file.write(f\"{audio_id}\\t{label}\\n\")\n",
        "\n",
        "    def save_original(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        og_path = out_path / f\"{audio_path.parent.stem}_{audio_path.name}\"\n",
        "        self.write_to_transcript(og_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        torchaudio.save(uri = og_path, src = audio, sample_rate = sample_rate)\n",
        "\n",
        "    def save_pitch_shifted(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        ps_path = out_path / f\"{audio_path.parent.stem}_ps_{audio_path.name}\"\n",
        "        self.write_to_transcript(ps_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        pitch_shifted_audio = self.augmentor.shift_pitch(audio, sample_rate)\n",
        "        torchaudio.save(uri= ps_path, src = pitch_shifted_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_noisy(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, snr: int, label: str, out_transcr_file: IO) -> None:\n",
        "        n_path = out_path / f\"{audio_path.parent.stem}_n_{audio_path.name}\"\n",
        "        self.write_to_transcript(n_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        noisy_audio = self.augmentor.add_background_crowd(audio, snr = snr)\n",
        "        torchaudio.save(uri= n_path, src = noisy_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_white_noisy(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, snr: int, variance: int,  label: str, out_transcr_file: IO) -> None:\n",
        "        wn_path = out_path / f\"{audio_path.parent.stem}_wn_{audio_path.name}\"\n",
        "        self.write_to_transcript(wn_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        white_noisy_audio = self.augmentor.add_white_noise(audio, snr = snr, variance = variance)\n",
        "        torchaudio.save(uri= wn_path, src = white_noisy_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_room_reverbed(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        rr_path = out_path / f\"{audio_path.parent.stem}_rr_{audio_path.name}\"\n",
        "        self.write_to_transcript(rr_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        room_reverbed_audio = self.augmentor.add_room_reverb(audio)\n",
        "        torchaudio.save(uri= rr_path, src = room_reverbed_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_speed_perturbed(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        sp_path = out_path / f\"{audio_path.parent.stem}_sp_{audio_path.name}\"\n",
        "        self.write_to_transcript(sp_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        speed_perturbed_audio = self.augmentor.perturb_speed(audio, sample_rate, factors = [0.9, 0.95, 1.05, 1.1])\n",
        "        torchaudio.save(uri= sp_path, src = speed_perturbed_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def save_low_passed(self, audio_path: Path, out_path: Path, audio: torch.Tensor, sample_rate: int, label: str, out_transcr_file: IO) -> None:\n",
        "        lpf_path = out_path / f\"{audio_path.parent.stem}_lpf_{audio_path.name}\"\n",
        "        low_passed_audio = self.augmentor.apply_low_pass_filter(audio, sample_rate)\n",
        "        self.write_to_transcript(lpf_path, label, out_transcr_file, ext = False)\n",
        "        if not self.save_aud:\n",
        "            return\n",
        "        torchaudio.save(uri= lpf_path, src = low_passed_audio, sample_rate = sample_rate )\n",
        "\n",
        "    def write_transcript_headers(self)->None:\n",
        "        header_1, header_2 = TranslitDict.DEFAULT_HEADERS\n",
        "        out_transcr_file.write(f\"{header_1}\\t{header_2}\\n\")\n",
        "\n",
        "\n",
        "    def preprocess(self) -> None:\n",
        "        if self.augmentor and self.resample_rate:\n",
        "            self.augmentor.resample_assets(self.resample_rate)\n",
        "\n",
        "        self.out_folder.mkdir()\n",
        "\n",
        "        out_transcr_path = self.out_folder / Path(self.out_transcr_name)\n",
        "        with open(out_transcr_path, mode = 'w', encoding = 'utf-8') as out_transcr_file:\n",
        "            self.preprocess_dir(self.data_folder, out_transcr_file)\n",
        "\n",
        "    def preprocess_dir(self, folder: Path, out_transcr_file: IO) -> None:\n",
        "        # If there are nested folders go inside and handle separately as a unit (of transcript file and audio files)\n",
        "        for path in folder.iterdir():\n",
        "            if self.skip and path.name in self.skip: #directory to be skipped\n",
        "                continue\n",
        "\n",
        "            if path.is_dir():\n",
        "                self.preprocess_dir(path, out_transcr_file)\n",
        "                continue\n",
        "\n",
        "        # the presence of a transcript file tells us that this is a concerned directory (an audio-transcript unit)\n",
        "        audio_label_dict = self.get_audio_label_dict(folder)\n",
        "\n",
        "        if not audio_label_dict:\n",
        "            return\n",
        "\n",
        "        out_path = self.out_folder\n",
        "        #self.write_transcript_headers()\n",
        "        for audio_path in audio_label_dict.keys():\n",
        "\n",
        "            label = audio_label_dict[audio_path]\n",
        "            audio, sample_rate = torchaudio.load(audio_path)\n",
        "\n",
        "            if not self.augmentor:\n",
        "                continue\n",
        "\n",
        "            if self.mono:\n",
        "                audio = self.augmentor.convert_to_mono(audio)\n",
        "\n",
        "            if self.resample_rate:\n",
        "                audio = self.augmentor.resample(audio, sample_rate, self.resample_rate)\n",
        "                sample_rate = self.resample_rate\n",
        "\n",
        "            self.save_original(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "\n",
        "            if not self.augment:\n",
        "                continue\n",
        "\n",
        "            self.save_pitch_shifted(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "            self.save_noisy(audio_path, out_path, audio, sample_rate, 20, label, out_transcr_file)\n",
        "            self.save_white_noisy(audio_path, out_path, audio, sample_rate, 20, 0.01, label, out_transcr_file)\n",
        "            self.save_room_reverbed(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "            self.save_speed_perturbed(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "            self.save_low_passed(audio_path, out_path, audio, sample_rate, label, out_transcr_file)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N2tCI-OSVZNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##COPY TEST FOLDER AND RUN TESTS"
      ],
      "metadata": {
        "id": "tJT7ajzzOUVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CS MANUAL DATASET"
      ],
      "metadata": {
        "id": "TaN8mfo9_j7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/data\n",
        "!mkdir /content/data"
      ],
      "metadata": {
        "id": "nYsGIFi0h_87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/"
      ],
      "metadata": {
        "id": "Ud96TvgfCS5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/* /content/data/\n",
        "# %cd /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/\n",
        "# !cp -r SG_Uniq_Poet SG_Palesha_Goverdhan SS_Dr_Jaya /content/data/\n",
        "# %cd ~"
      ],
      "metadata": {
        "id": "yoXMSml0CLZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/Transliteration Dictionary/Roman_Devanagari_Translit_Dict.json' /content/"
      ],
      "metadata": {
        "id": "fblh_fOkslmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translitr = RomanToDevaTransliterator(translit_dict='/content/Roman_Devanagari_Translit_Dict.json')"
      ],
      "metadata": {
        "id": "kTOsBFmHy8BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/data_out"
      ],
      "metadata": {
        "id": "T-3hIjUoOerC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####AUGMENT AND TRANSLITERATE AND SAVE AUDIO"
      ],
      "metadata": {
        "id": "QBos7DX_UN7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", transliterator = translitr, augmentor = AudioAugmentor(), augment = True)\n",
        "preprocessor.preprocess(); #To include extensions in file ids in transcript file see method write_to_transcript(). Perhaps this feature should be included as an attribute in AudioPreprocessor class.\n"
      ],
      "metadata": {
        "id": "JonvutPqy5Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####WRITE TRANSCRIPTS IN PROPER FORMAT WITHOUT TRANSLITERATION (AUDIO_ID TRANSCRIPT). NO AUDIO SAVING"
      ],
      "metadata": {
        "id": "Y0Z1k6hbUWlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", augmentor = AudioAugmentor(), save_aud=False)\n",
        "preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "Sq4B48JbUZJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####TRANSLITERATE AND AUGMENT BUT DON'T SAVE AUDIO\n",
        "This will only create transcript file. Will not actually augment the audio but the augmented audio's transcript (same as the original) are duplicated in the transcript file with proper labels (i.e. augmented audio ids)"
      ],
      "metadata": {
        "id": "NCIOQqFbUm9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", transliterator = translitr, augmentor = AudioAugmentor(), augment = True,  save_aud=False)\n",
        "preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "WOqmQvdzUrqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####AUGMENT BUT DON'T SAVE AUDIO NO TRANSLITERATION"
      ],
      "metadata": {
        "id": "ODUhUf2Mij5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", transliterator = None, augmentor = AudioAugmentor(), augment = True,  save_aud=False)\n",
        "preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "Ah4q3Pqoiov4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/data_out/transcript.txt | wc -l\n"
      ],
      "metadata": {
        "id": "cuKGiNTKjTiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data_out/transcript.txt /content/drive/MyDrive/MSICE/native_augmented_transcript.txt"
      ],
      "metadata": {
        "id": "FW1c21zyjiSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####SAVE TO DRIVE"
      ],
      "metadata": {
        "id": "MMD5haK3U-Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/data_out.zip /content/data_out\n",
        "!cp /content/data_out.zip /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual_Augmented.zip"
      ],
      "metadata": {
        "id": "e04EBIGuhA4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BHATTA DATASET RESAMPLING, CONVERSION TO MONO"
      ],
      "metadata": {
        "id": "OmGuJ8ZU6KQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/Bhatta_Normalized_DataSet/\n",
        "!mkdir --parents /content/Bhatta_Normalized_DataSet/bharat1/ /content/Bhatta_Normalized_DataSet/ganNeshsir3/"
      ],
      "metadata": {
        "id": "5sa96wFrxZJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/MSICE/Pure_Nepali_Labelled_Speech_Data/Dataset/Train/SECTEC /content/"
      ],
      "metadata": {
        "id": "Ftxs1uhRdfNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/SECTEC"
      ],
      "metadata": {
        "id": "RSBXfUwDdonB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def normalize_bhatta_dataset(data_fol:str, out_fol:str, mono: bool, new_sample_rate: int) -> None:\n",
        "    data_fol = Path(data_fol)\n",
        "    out_fol = Path(out_fol)\n",
        "\n",
        "    #AUDIO\n",
        "    audio_ext_pattern = re.compile(r\"\\.wav$\")\n",
        "    aug = AudioAugmentor()\n",
        "    for path in data_fol.iterdir():\n",
        "        if not path.is_file() or not audio_ext_pattern.search(path.name):\n",
        "            continue\n",
        "        audio, sample_rate = torchaudio.load(path)\n",
        "        if mono:\n",
        "            audio = aug.convert_to_mono(audio_tensor = audio)\n",
        "        if new_sample_rate:\n",
        "            sample_rate = new_sample_rate\n",
        "        torchaudio.save(uri = f\"{out_fol}/{path.name}\", src = audio, sample_rate=sample_rate)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ba1DR7a7yD5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize_bhatta_dataset(data_fol = \"/content/SECTEC/bharat1\", out_fol = \"/content/Bhatta_Normalized_DataSet/bharat1/\", mono = True, new_sample_rate = 16000)\n",
        "!cp /content/SECTEC/bharat1/SECTEC_bharat1.trans.txt /content/Bhatta_Normalized_DataSet/bharat1/"
      ],
      "metadata": {
        "id": "A9m7RqjI28dN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/Bhatta_Normalized_DataSet/bharat1/SECTEC_bharat1.trans.txt | wc -l\n",
        "!ls /content/Bhatta_Normalized_DataSet/bharat1/ | grep 'wav' | wc -l"
      ],
      "metadata": {
        "id": "F84yjvRY3r5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize_bhatta_dataset(data_fol = \"/content/SECTEC/ganNeshsir3\", out_fol = \"/content/Bhatta_Normalized_DataSet/ganNeshsir3\", mono = True, new_sample_rate = 16000)\n",
        "!cp /content/SECTEC/ganNeshsir3/SECTEC_ganNeshsir3.trans.txt /content/Bhatta_Normalized_DataSet/ganNeshsir3/"
      ],
      "metadata": {
        "id": "zNqui4cw4XUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/Bhatta_Normalized_DataSet/ganNeshsir3/SECTEC_ganNeshsir3.trans.txt | wc -l\n",
        "!ls /content/Bhatta_Normalized_DataSet/ganNeshsir3/ | grep 'wav' | wc -l"
      ],
      "metadata": {
        "id": "2Z4HlWdy6Ni0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp Bhatta_Normalized_DataSet.zip /content/drive/MyDrive/MSICE/"
      ],
      "metadata": {
        "id": "ZZMB-S6M6933"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/drive/MyDrive/MSICE"
      ],
      "metadata": {
        "id": "CRg6-hiE7L1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CS PREDETERMINED"
      ],
      "metadata": {
        "id": "m1mYGpfFQADv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r data/\n",
        "!rm -r data_out/"
      ],
      "metadata": {
        "id": "4LyQsHELQ8Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Predetermined/ /content/data/"
      ],
      "metadata": {
        "id": "CCgo5eFxQDNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####AUGMENT DON'T SAVE AUDIO NO TRANSLITERATION"
      ],
      "metadata": {
        "id": "ws9gg8TOQn32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", transliterator = None, augmentor = AudioAugmentor(), augment = False,  save_aud=False)\n",
        "preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "nSdkPyxtQJRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -20 /content/data_out/transcript.txt"
      ],
      "metadata": {
        "id": "1krBiavKQ1qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CS PREDETERMINED 2"
      ],
      "metadata": {
        "id": "Y4gKwrUYtd7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/data_out/\n",
        "# !rm -r /content/data/"
      ],
      "metadata": {
        "id": "VuwKr15ethod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/drive/MyDrive/MSICE/"
      ],
      "metadata": {
        "id": "kY5_Rot72DWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Predetermined_2/ /content/data/"
      ],
      "metadata": {
        "id": "B3gWxU_mtlli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####NO TRANSLITERATION, NO AUGMENTATION, SAVE AUDIO"
      ],
      "metadata": {
        "id": "nLeGzC9KuBzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", transcr_name = ('transcription.txt',), transliterator = None, augmentor = AudioAugmentor(), augment = False,  save_aud=True)\n",
        "preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "V5LQFdMzuA9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -40 /content/data_out/transcript.txt"
      ],
      "metadata": {
        "id": "T2CYgRVTuoLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/data_out/\n",
        "# !zip English_Nepali_CS_Data_Predetermined_2.zip *\n",
        "# %cd /content"
      ],
      "metadata": {
        "id": "lHdt2Vdw0dbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data_out/transcript.txt /content/drive/MyDrive/MSICE/pt_2_native_transcript.txt"
      ],
      "metadata": {
        "id": "gxK1nYL43uAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SLR54 SUBSET"
      ],
      "metadata": {
        "id": "jtoF3PX-KymS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/data_out/\n",
        "!rm -r /content/data/"
      ],
      "metadata": {
        "id": "QVQZyGy5UEq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/MSICE/SLR54_Subset.zip /content/"
      ],
      "metadata": {
        "id": "l7ptebDkQPV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir --parents /content/data/SLR54_Subset/"
      ],
      "metadata": {
        "id": "ESKAC1wJRhL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/SLR54_Subset.zip -d /content/data/SLR54_Subset/"
      ],
      "metadata": {
        "id": "DiZsBenOQUc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 /content/data/SLR54_Subset/transcription.txt"
      ],
      "metadata": {
        "id": "dnHvth4OUJZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/data_out/"
      ],
      "metadata": {
        "id": "V6YMtj-IX9oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def normalize_dataset(data_fol:str, out_fol:str, mono: bool, new_sample_rate: int) -> None:\n",
        "    data_fol = Path(data_fol)\n",
        "    out_fol = Path(out_fol)\n",
        "\n",
        "    #AUDIO\n",
        "    audio_ext_pattern = re.compile(r\"\\.flac$\")\n",
        "    aug = AudioAugmentor()\n",
        "    for path in data_fol.iterdir():\n",
        "        if not path.is_file() or not audio_ext_pattern.search(path.name):\n",
        "            continue\n",
        "        audio, sample_rate = torchaudio.load(path)\n",
        "        if mono:\n",
        "            audio = aug.convert_to_mono(audio_tensor = audio)\n",
        "        if new_sample_rate:\n",
        "            sample_rate = new_sample_rate\n",
        "        torchaudio.save(uri = f\"{out_fol}/{path.stem}.mp3\", src = audio, sample_rate=sample_rate)\n"
      ],
      "metadata": {
        "id": "AuILOUh0XDIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize_dataset(data_fol = '/content/data/SLR54_Subset/',out_fol = '/content/data_out/', mono = True, new_sample_rate = 16000)"
      ],
      "metadata": {
        "id": "i1VSb-8sXps0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/data_out/*|  wc -l"
      ],
      "metadata": {
        "id": "8o2NKSPhcSXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l /content/data/SLR54_Subset/transcription.txt"
      ],
      "metadata": {
        "id": "__uLZIkMcbkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/data_out/"
      ],
      "metadata": {
        "id": "Cf8_xaqhdqdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip SLR54_Subset_Normalized.zip *mp3"
      ],
      "metadata": {
        "id": "7WRyhd72dsEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "xDxkhthod2kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data_out/SLR54_Subset_Normalized.zip /content/drive/MyDrive/MSICE/"
      ],
      "metadata": {
        "id": "YsgBrwN2eBCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data/SLR54_Subset/transcription.txt /content/drive/MyDrive/MSICE/slr54_transcript.txt"
      ],
      "metadata": {
        "id": "ACgEku8LeHEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/drive/MyDrive/MSICE/SLR54_Subset.zip"
      ],
      "metadata": {
        "id": "fvMhllvzeQFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/drive/MyDrive/MSICE/"
      ],
      "metadata": {
        "id": "kke82aEceVSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LOKNATH KOIRALA CHEKHOV DATASET"
      ],
      "metadata": {
        "id": "4s7Gmttgkq2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r data_out/\n",
        "!rm -r data/"
      ],
      "metadata": {
        "id": "rok2_0j7le7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/data/"
      ],
      "metadata": {
        "id": "hYsk3hRupW6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -hl /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/Loknath_Koirala_About_Love_Chekhov/"
      ],
      "metadata": {
        "id": "5poq6jgnkxZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/MSICE/English_Nepali_CS_Data_Manual/Loknath_Koirala_About_Love_Chekhov /content/data/Loknath_Koirala_About_Love_Chekhov"
      ],
      "metadata": {
        "id": "GuChyVSHlSn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -hl /content/data/Loknath_Koirala_About_Love_Chekhov/"
      ],
      "metadata": {
        "id": "GJpYFqj9oy1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AudioPreprocessor(data_folder = \"/content/data/\", out_folder = \"/content/data_out/\", transliterator = None, augmentor = AudioAugmentor(), augment = False,  save_aud=True)\n",
        "preprocessor.preprocess()"
      ],
      "metadata": {
        "id": "LgTwpm6qlg9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -hl /content/data_out/"
      ],
      "metadata": {
        "id": "yNaE3vXdplMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -10 /content/data_out/transcript.txt"
      ],
      "metadata": {
        "id": "pPh7s1IypqKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/data_out/"
      ],
      "metadata": {
        "id": "1__ghzIqp4rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip LK_About_Love_Chekhov.zip *"
      ],
      "metadata": {
        "id": "3I856t37p8NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "yvMkEckSqGuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data_out/LK_About_Love_Chekhov.zip /content/drive/MyDrive/MSICE/"
      ],
      "metadata": {
        "id": "OKeR4WnkqYDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data_out/transcript.txt /content/"
      ],
      "metadata": {
        "id": "NzZmrut6qcsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/transcript.txt '/content/drive/My Drive/MSICE/Loknath_Koirala_About_Love_Chekhov_transcript.txt'"
      ],
      "metadata": {
        "id": "gVTHGW2gqge1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}